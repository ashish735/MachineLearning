{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 131
    },
    "colab_type": "code",
    "id": "feLLqBM0uUBw",
    "outputId": "3b06d7a8-8d15-4402-deda-85c0b479985a"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from time import time\n",
    "from tensorflow.python.keras.callbacks import TensorBoard\n",
    "import re\n",
    "\n",
    "#from google.colab import drive\n",
    "#drive.mount('/content/gdrive')\n",
    "# Dataset is now stored in a Pandas Dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_csv('DonorsChoose_LSTM.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 170
    },
    "colab_type": "code",
    "id": "hw-XIwcOut0g",
    "outputId": "d15613be-5f52-46f9-e41d-80c05eb9639a"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>teacher_prefix</th>\n",
       "      <th>school_state</th>\n",
       "      <th>project_grade_category</th>\n",
       "      <th>teacher_number_of_previously_posted_projects</th>\n",
       "      <th>project_is_approved</th>\n",
       "      <th>price</th>\n",
       "      <th>quantity</th>\n",
       "      <th>clean_essay</th>\n",
       "      <th>clean_title</th>\n",
       "      <th>clean_categories</th>\n",
       "      <th>clean_subcategories</th>\n",
       "      <th>Is_digit_present</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>101926</th>\n",
       "      <td>Ms.</td>\n",
       "      <td>FL</td>\n",
       "      <td>Grades 9-12</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>297.87</td>\n",
       "      <td>2</td>\n",
       "      <td>students sit talk discovered various nationali...</td>\n",
       "      <td>let illustrate</td>\n",
       "      <td>Music_Arts</td>\n",
       "      <td>VisualArts</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       teacher_prefix school_state project_grade_category  \\\n",
       "101926            Ms.           FL            Grades 9-12   \n",
       "\n",
       "        teacher_number_of_previously_posted_projects  project_is_approved  \\\n",
       "101926                                             2                    1   \n",
       "\n",
       "         price  quantity                                        clean_essay  \\\n",
       "101926  297.87         2  students sit talk discovered various nationali...   \n",
       "\n",
       "           clean_title clean_categories clean_subcategories  Is_digit_present  \n",
       "101926  let illustrate       Music_Arts          VisualArts                 0  "
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[101926:101927]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "j2SOlGV1huXi"
   },
   "outputs": [],
   "source": [
    "data['total_text']=data['clean_essay'].map(str) + data['clean_title'].map(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "GNbcf5EE6q1g",
    "outputId": "8286e7c9-d602-4a98-9e93-f3cbb5925336"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape: (98323, 13)\n",
      "Test data shape: (10925, 13)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score\n",
    "train, test = train_test_split(data, random_state=123, shuffle=True, test_size=0.1)\n",
    "print(\"Training data shape:\", train.shape)\n",
    "print(\"Test data shape:\", test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train=train.reset_index()\n",
    "test=test.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>teacher_prefix</th>\n",
       "      <th>school_state</th>\n",
       "      <th>project_grade_category</th>\n",
       "      <th>teacher_number_of_previously_posted_projects</th>\n",
       "      <th>project_is_approved</th>\n",
       "      <th>price</th>\n",
       "      <th>quantity</th>\n",
       "      <th>clean_essay</th>\n",
       "      <th>clean_title</th>\n",
       "      <th>clean_categories</th>\n",
       "      <th>clean_subcategories</th>\n",
       "      <th>Is_digit_present</th>\n",
       "      <th>total_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>101926</td>\n",
       "      <td>Ms.</td>\n",
       "      <td>FL</td>\n",
       "      <td>Grades 9-12</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>297.87</td>\n",
       "      <td>2</td>\n",
       "      <td>students sit talk discovered various nationali...</td>\n",
       "      <td>let illustrate</td>\n",
       "      <td>Music_Arts</td>\n",
       "      <td>VisualArts</td>\n",
       "      <td>0</td>\n",
       "      <td>students sit talk discovered various nationali...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>83948</td>\n",
       "      <td>Mrs.</td>\n",
       "      <td>CA</td>\n",
       "      <td>Grades 3-5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>194.93</td>\n",
       "      <td>11</td>\n",
       "      <td>imagine coming school every day knowing odds n...</td>\n",
       "      <td>rekindling science</td>\n",
       "      <td>Math_Science SpecialNeeds</td>\n",
       "      <td>EnvironmentalScience SpecialNeeds</td>\n",
       "      <td>0</td>\n",
       "      <td>imagine coming school every day knowing odds n...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    index teacher_prefix school_state project_grade_category  \\\n",
       "0  101926            Ms.           FL            Grades 9-12   \n",
       "1   83948           Mrs.           CA             Grades 3-5   \n",
       "\n",
       "   teacher_number_of_previously_posted_projects  project_is_approved   price  \\\n",
       "0                                             2                    1  297.87   \n",
       "1                                             0                    1  194.93   \n",
       "\n",
       "   quantity                                        clean_essay  \\\n",
       "0         2  students sit talk discovered various nationali...   \n",
       "1        11  imagine coming school every day knowing odds n...   \n",
       "\n",
       "          clean_title           clean_categories  \\\n",
       "0      let illustrate                 Music_Arts   \n",
       "1  rekindling science  Math_Science SpecialNeeds   \n",
       "\n",
       "                 clean_subcategories  Is_digit_present  \\\n",
       "0                         VisualArts                 0   \n",
       "1  EnvironmentalScience SpecialNeeds                 0   \n",
       "\n",
       "                                          total_text  \n",
       "0  students sit talk discovered various nationali...  \n",
       "1  imagine coming school every day knowing odds n...  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distribution of positive and negative data points "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ax = data.groupby(\"project_is_approved\")[\"project_is_approved\"].count().plot.bar()\n",
    "\n",
    "# create a list to collect the plt.patches data\n",
    "totals = []\n",
    "\n",
    "# find the values and append to list\n",
    "for i in ax.patches:\n",
    "    totals.append(i.get_height())\n",
    "\n",
    "# set individual bar lables using above list\n",
    "total = sum(totals)\n",
    "\n",
    "# set individual bar lables using above list\n",
    "for i in ax.patches:\n",
    "    # get_x pulls left or right; get_height pushes up or down\n",
    "    ax.text(i.get_x()-.03, i.get_height()+.5, \\\n",
    "            str(round((i.get_height()/total)*100, 2))+'%', fontsize=15,\n",
    "                color='dimgrey')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing pre trained Glove vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "h0vxZQ6d6RQD"
   },
   "outputs": [],
   "source": [
    "import io\n",
    "import pickle\n",
    "with io.open('glove_vectors.txt', 'rb') as f:\n",
    "    glove_model = pickle.load(f)\n",
    "    glove_words =  set(glove_model.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing with Keras tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.text import Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4H-w2f2qmsMD"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "token = Tokenizer()\n",
    "\n",
    "token.fit_on_texts(train['total_text'])\n",
    "train['total_text']=token.texts_to_sequences(train['total_text'])\n",
    "test['total_text']=token.texts_to_sequences(test['total_text'])\n",
    "text_size = len(token.word_index) + 1\n",
    "\n",
    "# create a weight matrix for words in training docs --code copied from https://machinelearningmastery.com/use-word-embedding-layers-deep-learning-keras/\n",
    "embedding_matrix = np.zeros((text_size, 300))\n",
    "for word, i in token.word_index.items():\n",
    "    embedding_vector = glove_model.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        embedding_matrix[i] = embedding_vector\n",
    "\n",
    "token = Tokenizer()\n",
    "\n",
    "token.fit_on_texts(train['clean_categories'])\n",
    "train['clean_categories']=token.texts_to_sequences(train['clean_categories'])\n",
    "test['clean_categories']=token.texts_to_sequences(test['clean_categories'])\n",
    "category_size = len(token.word_index) + 1\n",
    "\n",
    "token = Tokenizer()\n",
    "\n",
    "token.fit_on_texts(train['teacher_prefix'])\n",
    "train['teacher_prefix']=token.texts_to_sequences(train['teacher_prefix'])\n",
    "test['teacher_prefix']=token.texts_to_sequences(test['teacher_prefix'])\n",
    "prefix_size = len(token.word_index) + 1\n",
    "\n",
    "token = Tokenizer()\n",
    "\n",
    "token.fit_on_texts(train['school_state'])\n",
    "train['school_state']=token.texts_to_sequences(train['school_state'])\n",
    "test['school_state']=token.texts_to_sequences(test['school_state'])\n",
    "state_size = len(token.word_index) + 1\n",
    "\n",
    "token = Tokenizer()\n",
    "\n",
    "token.fit_on_texts(train['project_grade_category'])\n",
    "train['project_grade_category']=token.texts_to_sequences(train['project_grade_category'])\n",
    "test['project_grade_category']=token.texts_to_sequences(test['project_grade_category'])\n",
    "grade_size = len(token.word_index) + 1\n",
    "\n",
    "token = Tokenizer()\n",
    "\n",
    "token.fit_on_texts(train['clean_subcategories'])\n",
    "train['clean_subcategories']=token.texts_to_sequences(train['clean_subcategories'])\n",
    "test['clean_subcategories']=token.texts_to_sequences(test['clean_subcategories'])\n",
    "subcategory_size = len(token.word_index) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 253
    },
    "colab_type": "code",
    "id": "MoC0rE-i1HxY",
    "outputId": "f3fe331a-653b-4df4-a2d6-2981ef00d471"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(67062, 300)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DvlGvuTFY8CZ"
   },
   "outputs": [],
   "source": [
    "train.drop(['clean_essay','clean_title','index'] , axis=1, inplace=True)\n",
    "test.drop(['clean_essay','clean_title','index'] , axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>teacher_prefix</th>\n",
       "      <th>school_state</th>\n",
       "      <th>project_grade_category</th>\n",
       "      <th>teacher_number_of_previously_posted_projects</th>\n",
       "      <th>project_is_approved</th>\n",
       "      <th>price</th>\n",
       "      <th>quantity</th>\n",
       "      <th>clean_essay</th>\n",
       "      <th>clean_title</th>\n",
       "      <th>clean_categories</th>\n",
       "      <th>clean_subcategories</th>\n",
       "      <th>Is_digit_present</th>\n",
       "      <th>total_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>98321</th>\n",
       "      <td>28030</td>\n",
       "      <td>[2]</td>\n",
       "      <td>[2]</td>\n",
       "      <td>[1, 2, 3]</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>471.0</td>\n",
       "      <td>15</td>\n",
       "      <td>best part teaching second grade hands enthusia...</td>\n",
       "      <td>reading learn non fiction</td>\n",
       "      <td>[3, 4, 1, 2]</td>\n",
       "      <td>[10, 1]</td>\n",
       "      <td>0</td>\n",
       "      <td>[30, 97, 95, 124, 50, 375, 28, 638, 814, 4, 19...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98322</th>\n",
       "      <td>15725</td>\n",
       "      <td>[2]</td>\n",
       "      <td>[18]</td>\n",
       "      <td>[1, 2, 3]</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>867.5</td>\n",
       "      <td>9</td>\n",
       "      <td>students mix special needs students thrive chi...</td>\n",
       "      <td>multimedia learning enhances communication</td>\n",
       "      <td>[1, 2, 3, 4]</td>\n",
       "      <td>[1, 2]</td>\n",
       "      <td>0</td>\n",
       "      <td>[973, 27, 459, 122, 836, 226, 3, 459, 4077, 42...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       index teacher_prefix school_state project_grade_category  \\\n",
       "98321  28030            [2]          [2]              [1, 2, 3]   \n",
       "98322  15725            [2]         [18]              [1, 2, 3]   \n",
       "\n",
       "       teacher_number_of_previously_posted_projects  project_is_approved  \\\n",
       "98321                                             1                    1   \n",
       "98322                                             1                    0   \n",
       "\n",
       "       price  quantity                                        clean_essay  \\\n",
       "98321  471.0        15  best part teaching second grade hands enthusia...   \n",
       "98322  867.5         9  students mix special needs students thrive chi...   \n",
       "\n",
       "                                      clean_title clean_categories  \\\n",
       "98321                   reading learn non fiction     [3, 4, 1, 2]   \n",
       "98322  multimedia learning enhances communication     [1, 2, 3, 4]   \n",
       "\n",
       "      clean_subcategories  Is_digit_present  \\\n",
       "98321             [10, 1]                 0   \n",
       "98322              [1, 2]                 0   \n",
       "\n",
       "                                              total_text  \n",
       "98321  [30, 97, 95, 124, 50, 375, 28, 638, 814, 4, 19...  \n",
       "98322  [973, 27, 459, 122, 836, 226, 3, 459, 4077, 42...  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.tail(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting data in the form of Dictionary which then will be given as a input to Deep Learning Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from numpy import array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train={}\n",
    "\n",
    "X_train[\"posted_projects\"]= array(train[\"teacher_number_of_previously_posted_projects\"]).reshape(len(train),1)\n",
    "X_train[\"price\"]= array(train[\"price\"]).reshape(len(train),1)\n",
    "X_train[\"quantity\"]= array(train[\"quantity\"]).reshape(len(train),1)\n",
    "X_train[\"Is_digit_present\"]= array(train[\"Is_digit_present\"]).reshape(len(train),1)\n",
    "        \n",
    "X_train[\"teacher_prefix\"] = pad_sequences(train[\"teacher_prefix\"], maxlen=1)\n",
    "X_train[\"school_state\"] = pad_sequences(train[\"school_state\"], maxlen=1)\n",
    "X_train[\"project_grade_category\"] = pad_sequences(train[\"project_grade_category\"], maxlen=3)\n",
    "        \n",
    "X_train[\"total_text\"] = pad_sequences(train[\"total_text\"], maxlen=300)\n",
    "X_train[\"clean_categories\"] = pad_sequences(train[\"clean_categories\"], maxlen=4)\n",
    "X_train[\"clean_subcategories\"] = pad_sequences(train[\"clean_subcategories\"], maxlen=4)\n",
    "\n",
    "X_train[\"output\"]= array(train[\"project_is_approved\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "d4LiUpuV8iER"
   },
   "outputs": [],
   "source": [
    "X_test={}\n",
    "\n",
    "X_test[\"posted_projects\"]= array(test[\"teacher_number_of_previously_posted_projects\"]).reshape(len(test),1)\n",
    "X_test[\"price\"]= array(test[\"price\"]).reshape(len(test),1)\n",
    "X_test[\"quantity\"]= array(test[\"quantity\"]).reshape(len(test),1)\n",
    "X_test[\"Is_digit_present\"]= array(test[\"Is_digit_present\"]).reshape(len(test),1)\n",
    "        \n",
    "X_test[\"teacher_prefix\"]= pad_sequences(test[\"teacher_prefix\"], maxlen=1)\n",
    "X_test[\"school_state\"]= pad_sequences(test[\"school_state\"], maxlen=1)\n",
    "X_test[\"project_grade_category\"]= pad_sequences(test[\"project_grade_category\"], maxlen=3)\n",
    "        \n",
    "X_test[\"total_text\"]= pad_sequences(test[\"total_text\"], maxlen=300)\n",
    "X_test[\"clean_categories\"]= pad_sequences(test[\"clean_categories\"], maxlen=4)\n",
    "X_test[\"clean_subcategories\"]= pad_sequences(test[\"clean_subcategories\"], maxlen=4)\n",
    "\n",
    "X_test[\"output\"]= array(test[\"project_is_approved\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.initializers import he_normal\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adam\n",
    "from keras.layers import Input, BatchNormalization, Embedding, LSTM, Flatten, concatenate, Dense, Dropout\n",
    "#import tensorflow as tf\n",
    "#sess = tf.Session()\n",
    "\n",
    "#from keras import backend as K\n",
    "#K.set_session(sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.6.8\n"
     ]
    }
   ],
   "source": [
    "import platform\n",
    "print(platform.python_version())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "total_text (InputLayer)         (None, 300)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "posted_projects (InputLayer)    (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "price (InputLayer)              (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "Is_digit_present (InputLayer)   (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "quantity (InputLayer)           (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_91 (Embedding)        (None, 300, 300)     20118600    total_text[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "clean_categories (InputLayer)   (None, 4)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "clean_subcategories (InputLayer (None, 4)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "school_state (InputLayer)       (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "teacher_prefix (InputLayer)     (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "project_grade_category (InputLa (None, 3)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_31 (Concatenate)    (None, 4)            0           posted_projects[0][0]            \n",
      "                                                                 price[0][0]                      \n",
      "                                                                 Is_digit_present[0][0]           \n",
      "                                                                 quantity[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lstm_16 (LSTM)                  (None, 300, 12)      15024       embedding_91[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "embedding_92 (Embedding)        (None, 4, 4)         64          clean_categories[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "embedding_93 (Embedding)        (None, 4, 4)         152         clean_subcategories[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "embedding_94 (Embedding)        (None, 1, 8)         416         school_state[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "embedding_95 (Embedding)        (None, 1, 2)         12          teacher_prefix[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "embedding_96 (Embedding)        (None, 3, 2)         20          project_grade_category[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dense_61 (Dense)                (None, 4)            20          concatenate_31[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "flatten_91 (Flatten)            (None, 3600)         0           lstm_16[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "flatten_92 (Flatten)            (None, 16)           0           embedding_92[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "flatten_93 (Flatten)            (None, 16)           0           embedding_93[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "flatten_94 (Flatten)            (None, 8)            0           embedding_94[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "flatten_95 (Flatten)            (None, 2)            0           embedding_95[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "flatten_96 (Flatten)            (None, 6)            0           embedding_96[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_32 (Concatenate)    (None, 3652)         0           dense_61[0][0]                   \n",
      "                                                                 flatten_91[0][0]                 \n",
      "                                                                 flatten_92[0][0]                 \n",
      "                                                                 flatten_93[0][0]                 \n",
      "                                                                 flatten_94[0][0]                 \n",
      "                                                                 flatten_95[0][0]                 \n",
      "                                                                 flatten_96[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_62 (Dense)                (None, 8)            29224       concatenate_32[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_44 (BatchNo (None, 8)            32          dense_62[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_63 (Dense)                (None, 4)            36          batch_normalization_44[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dense_64 (Dense)                (None, 2)            10          dense_63[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "final_output (Dense)            (None, 1)            3           dense_64[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 20,163,613\n",
      "Trainable params: 44,997\n",
      "Non-trainable params: 20,118,616\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "\n",
    "    # Input layers\n",
    "previously_posted_projects = Input(shape=(1,), name=\"posted_projects\")\n",
    "price = Input(shape=(1,), name=\"price\")\n",
    "digit_present = Input(shape=(1,), name=\"Is_digit_present\")\n",
    "quantity = Input(shape=(1,), name=\"quantity\")\n",
    "    \n",
    "    \n",
    "school_state = Input(shape=(1,), name=\"school_state\")\n",
    "teacher_prefix = Input(shape=(1,), name=\"teacher_prefix\")\n",
    "project_grade= Input(shape=(3,), name=\"project_grade_category\")\n",
    "    \n",
    "total_text = Input(shape=(300,), name=\"total_text\")\n",
    "clean_categories = Input(shape=(4,), name=\"clean_categories\")\n",
    "clean_subcategories = Input(shape=(4,), name=\"clean_subcategories\")\n",
    "    \n",
    "    # Batch normalization layer\n",
    "#previously_posted_projects_bn = BatchNormalization(axis=1, momentum=0.99, epsilon=0.001, center=True, scale=True, beta_initializer='zeros', gamma_initializer='ones', moving_mean_initializer='zeros', moving_variance_initializer='ones')(previously_posted_projects)\n",
    "#price_bn = BatchNormalization(axis=1, momentum=0.99, epsilon=0.001, center=True, scale=True, beta_initializer='zeros', gamma_initializer='ones', moving_mean_initializer='zeros', moving_variance_initializer='ones')(price)\n",
    "#quantity_bn = BatchNormalization(axis=1, momentum=0.99, epsilon=0.001, center=True, scale=True, beta_initializer='zeros', gamma_initializer='ones', moving_mean_initializer='zeros', moving_variance_initializer='ones')(quantity)\n",
    "    \n",
    "    \n",
    "    \n",
    "    # Embedding layers\n",
    "emb_text_layer = Embedding(text_size, 300, weights=[embedding_matrix],  trainable=False)\n",
    "emb_category_layer = Embedding(category_size, 4)\n",
    "emb_subcategory_layer = Embedding(subcategory_size, 4)\n",
    "    \n",
    "emb_state_layer = Embedding(state_size, 8)\n",
    "emb_prefix_layer = Embedding(prefix_size, 2)\n",
    "emb_grade_layer = Embedding(grade_size, 2)\n",
    "    \n",
    "    # Giving Input to Embedding layers\n",
    "emb_text = emb_text_layer(total_text)\n",
    "emb_category =emb_category_layer(clean_categories)\n",
    "emb_subcategory =emb_subcategory_layer(clean_subcategories)\n",
    "    \n",
    "emb_state =emb_state_layer(school_state)\n",
    "emb_prefix =emb_prefix_layer(teacher_prefix)\n",
    "emb_grade =emb_grade_layer(project_grade)\n",
    "    \n",
    "        \n",
    "    # LSTM layers\n",
    "lstm_text = LSTM(12, activation=\"relu\", return_sequences=True)(emb_text)\n",
    "    \n",
    "    # Flatten layers\n",
    "flatten_text =Flatten()(lstm_text)\n",
    "flatten_category =Flatten()(emb_category)\n",
    "flatten_subcategory =keras.layers.Flatten()(emb_subcategory)\n",
    "    \n",
    "flatten_state =Flatten()(emb_state)\n",
    "flatten_prefix =Flatten()(emb_prefix)\n",
    "flatten_grade =Flatten()(emb_grade)\n",
    "    \n",
    "    # concatenation of all numeric layers\n",
    "numeric= concatenate([previously_posted_projects,\n",
    "                                      price,\n",
    "                                      digit_present,\n",
    "                                      quantity])\n",
    "    # Dense layer\n",
    "dense_numeric =Dense(4, activation='relu',kernel_initializer=he_normal(seed=5))(numeric)\n",
    "    \n",
    "    # Merge all layers into one\n",
    "x = concatenate([dense_numeric,\n",
    "                                 flatten_text,\n",
    "                                 flatten_category,\n",
    "                                 flatten_subcategory,\n",
    "                                 flatten_state,\n",
    "                                 flatten_prefix,\n",
    "                                 flatten_grade])\n",
    "    \n",
    "dense_x =Dense(8, activation='relu',kernel_initializer=he_normal(seed=3))(x)\n",
    "    \n",
    "dense_x_bn= BatchNormalization(axis=1, momentum=0.99, epsilon=0.001, center=True, scale=True, beta_initializer='zeros', gamma_initializer='ones', moving_mean_initializer='zeros', moving_variance_initializer='ones')(dense_x)\n",
    "    \n",
    "#drop_x =Dropout(0.5)(dense_x_bn)\n",
    "    \n",
    "dense2_x =Dense(4, activation='relu',kernel_initializer=he_normal(seed=1))(dense_x_bn)\n",
    "    \n",
    "#drop2_x =Dropout(0.5)(dense2_x)\n",
    "    \n",
    "dense3_x =Dense(2, activation='relu',kernel_initializer=he_normal(seed=2))(dense2_x)\n",
    "    \n",
    "    # Dense layers\n",
    "    #x = keras.layers.Dense(128, activation=\"relu\")(x)\n",
    "\n",
    "    # Output layers\n",
    "output = Dense(1, activation=\"sigmoid\", name='final_output')(dense3_x)\n",
    "    \n",
    "\n",
    "\n",
    "model = Model(inputs=[previously_posted_projects,price,digit_present,quantity,school_state,teacher_prefix,project_grade,total_text,clean_categories,clean_subcategories], outputs=[output])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AUC metric Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "def roc_auc(y_true, y_pred):\n",
    "    auc = tf.metrics.auc(y_true, y_pred,weights=None,num_thresholds=200)[1]\n",
    "    keras.backend.get_session().run(tf.local_variables_initializer()) # use to reset the local variables created by tf.metrics.auc\n",
    "    return auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 98323 samples, validate on 10925 samples\n",
      "Epoch 1/40\n",
      "98323/98323 [==============================] - 46s 465us/step - loss: 0.5809 - roc_auc: 0.4886 - val_loss: 0.4358 - val_roc_auc: 0.4888\n",
      "Epoch 2/40\n",
      "98323/98323 [==============================] - 38s 386us/step - loss: 0.4177 - roc_auc: 0.5093 - val_loss: 0.4318 - val_roc_auc: 0.5271\n",
      "Epoch 3/40\n",
      "98323/98323 [==============================] - 38s 386us/step - loss: 0.4061 - roc_auc: 0.5437 - val_loss: 0.4327 - val_roc_auc: 0.5590\n",
      "Epoch 4/40\n",
      "98323/98323 [==============================] - 38s 387us/step - loss: 0.4004 - roc_auc: 0.5727 - val_loss: 0.4323 - val_roc_auc: 0.5832\n",
      "Epoch 5/40\n",
      "98323/98323 [==============================] - 38s 389us/step - loss: 0.3962 - roc_auc: 0.5928 - val_loss: 0.4339 - val_roc_auc: 0.6011\n",
      "Epoch 6/40\n",
      "98323/98323 [==============================] - 38s 387us/step - loss: 0.3941 - roc_auc: 0.6087 - val_loss: 0.4346 - val_roc_auc: 0.6142\n",
      "Epoch 7/40\n",
      "98323/98323 [==============================] - 38s 386us/step - loss: 0.3900 - roc_auc: 0.6202 - val_loss: 0.4356 - val_roc_auc: 0.6252\n",
      "Epoch 8/40\n",
      "98323/98323 [==============================] - 38s 383us/step - loss: 0.3875 - roc_auc: 0.6303 - val_loss: 0.4365 - val_roc_auc: 0.6344\n",
      "Epoch 9/40\n",
      "98323/98323 [==============================] - 38s 390us/step - loss: 0.3860 - roc_auc: 0.6386 - val_loss: 0.4400 - val_roc_auc: 0.6416\n",
      "Epoch 10/40\n",
      "98323/98323 [==============================] - 38s 386us/step - loss: 0.3837 - roc_auc: 0.6454 - val_loss: 0.4401 - val_roc_auc: 0.6480\n",
      "Epoch 11/40\n",
      "98323/98323 [==============================] - 38s 388us/step - loss: 0.3841 - roc_auc: 0.6508 - val_loss: 0.4418 - val_roc_auc: 0.6531\n",
      "Epoch 12/40\n",
      "98323/98323 [==============================] - 38s 388us/step - loss: 0.3827 - roc_auc: 0.6557 - val_loss: 0.4435 - val_roc_auc: 0.6574\n",
      "Epoch 13/40\n",
      "98323/98323 [==============================] - 38s 385us/step - loss: 0.3804 - roc_auc: 0.6596 - val_loss: 0.4436 - val_roc_auc: 0.6615\n",
      "Epoch 14/40\n",
      "98323/98323 [==============================] - 38s 386us/step - loss: 0.3779 - roc_auc: 0.6637 - val_loss: 0.4459 - val_roc_auc: 0.6655\n",
      "Epoch 15/40\n",
      "98323/98323 [==============================] - 38s 390us/step - loss: 0.3773 - roc_auc: 0.6674 - val_loss: 0.4506 - val_roc_auc: 0.6689\n",
      "Epoch 16/40\n",
      "98323/98323 [==============================] - 38s 386us/step - loss: 0.3783 - roc_auc: 0.6705 - val_loss: 0.4488 - val_roc_auc: 0.6718\n",
      "Epoch 17/40\n",
      "98323/98323 [==============================] - 38s 388us/step - loss: 0.3782 - roc_auc: 0.6732 - val_loss: 0.4467 - val_roc_auc: 0.6743\n",
      "Epoch 18/40\n",
      "98323/98323 [==============================] - 38s 387us/step - loss: 0.3760 - roc_auc: 0.6756 - val_loss: 0.4478 - val_roc_auc: 0.6768\n",
      "Epoch 19/40\n",
      "98323/98323 [==============================] - 38s 388us/step - loss: 0.3748 - roc_auc: 0.6782 - val_loss: 0.4462 - val_roc_auc: 0.6792\n",
      "Epoch 20/40\n",
      "98323/98323 [==============================] - 38s 385us/step - loss: 0.3743 - roc_auc: 0.6805 - val_loss: 0.4488 - val_roc_auc: 0.6814\n",
      "Epoch 21/40\n",
      "98323/98323 [==============================] - 38s 389us/step - loss: 0.3726 - roc_auc: 0.6826 - val_loss: 0.4508 - val_roc_auc: 0.6835\n",
      "Epoch 22/40\n",
      "98323/98323 [==============================] - 38s 384us/step - loss: 0.3737 - roc_auc: 0.6845 - val_loss: 0.4520 - val_roc_auc: 0.6853\n",
      "Epoch 23/40\n",
      "98323/98323 [==============================] - 38s 386us/step - loss: 0.3712 - roc_auc: 0.6864 - val_loss: 0.4598 - val_roc_auc: 0.6871\n",
      "Epoch 24/40\n",
      "98323/98323 [==============================] - 38s 384us/step - loss: 0.3727 - roc_auc: 0.6880 - val_loss: 0.4632 - val_roc_auc: 0.6886\n",
      "Epoch 25/40\n",
      "98323/98323 [==============================] - 38s 384us/step - loss: 0.3711 - roc_auc: 0.6894 - val_loss: 0.4626 - val_roc_auc: 0.6900\n",
      "Epoch 26/40\n",
      "98323/98323 [==============================] - 39s 399us/step - loss: 0.3697 - roc_auc: 0.6909 - val_loss: 0.4558 - val_roc_auc: 0.6915\n",
      "Epoch 27/40\n",
      "98323/98323 [==============================] - 43s 438us/step - loss: 0.3706 - roc_auc: 0.6923 - val_loss: 0.4581 - val_roc_auc: 0.6928\n",
      "Epoch 28/40\n",
      "98323/98323 [==============================] - 38s 387us/step - loss: 0.3681 - roc_auc: 0.6936 - val_loss: 0.4646 - val_roc_auc: 0.6942\n",
      "Epoch 29/40\n",
      "98323/98323 [==============================] - 39s 392us/step - loss: 0.3694 - roc_auc: 0.6948 - val_loss: 0.4679 - val_roc_auc: 0.6953\n",
      "Epoch 30/40\n",
      "98323/98323 [==============================] - 38s 386us/step - loss: 0.3663 - roc_auc: 0.6960 - val_loss: 0.4630 - val_roc_auc: 0.6966\n",
      "Epoch 31/40\n",
      "98323/98323 [==============================] - 38s 385us/step - loss: 0.3676 - roc_auc: 0.6973 - val_loss: 0.4686 - val_roc_auc: 0.6977\n",
      "Epoch 32/40\n",
      "98323/98323 [==============================] - 38s 386us/step - loss: 0.3661 - roc_auc: 0.6983 - val_loss: 0.4718 - val_roc_auc: 0.6988\n",
      "Epoch 33/40\n",
      "98323/98323 [==============================] - 38s 383us/step - loss: 0.3643 - roc_auc: 0.6995 - val_loss: 0.4767 - val_roc_auc: 0.6999\n",
      "Epoch 34/40\n",
      "98323/98323 [==============================] - 38s 386us/step - loss: 0.3663 - roc_auc: 0.7004 - val_loss: 0.4808 - val_roc_auc: 0.7007\n",
      "Epoch 35/40\n",
      "98323/98323 [==============================] - 38s 383us/step - loss: 0.3663 - roc_auc: 0.7012 - val_loss: 0.4775 - val_roc_auc: 0.7015\n",
      "Epoch 36/40\n",
      "98323/98323 [==============================] - 38s 391us/step - loss: 0.3663 - roc_auc: 0.7020 - val_loss: 0.4655 - val_roc_auc: 0.7023\n",
      "Epoch 37/40\n",
      "98323/98323 [==============================] - 38s 386us/step - loss: 0.3644 - roc_auc: 0.7029 - val_loss: 0.4799 - val_roc_auc: 0.7032\n",
      "Epoch 38/40\n",
      "98323/98323 [==============================] - 38s 389us/step - loss: 0.3646 - roc_auc: 0.7037 - val_loss: 0.4824 - val_roc_auc: 0.7039\n",
      "Epoch 39/40\n",
      "98323/98323 [==============================] - 38s 389us/step - loss: 0.3629 - roc_auc: 0.7044 - val_loss: 0.4767 - val_roc_auc: 0.7047\n",
      "Epoch 40/40\n",
      "98323/98323 [==============================] - 38s 384us/step - loss: 0.3632 - roc_auc: 0.7052 - val_loss: 0.4801 - val_roc_auc: 0.7055\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x198b5b67828>"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "tb =TensorBoard(log_dir=\"logs/{}\".format(time()))\n",
    "\n",
    "model.compile(optimizer = Adam(lr=1e-2),\n",
    "                  loss = {'final_output': 'binary_crossentropy'},\n",
    "                  metrics = [roc_auc])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "model.fit({\"posted_projects\":X_train['posted_projects'], \"price\":X_train['price'],\n",
    "              \"Is_digit_present\":X_train['Is_digit_present'], \"quantity\":X_train['quantity'],\n",
    "              \"school_state\":X_train['school_state'], \"teacher_prefix\":X_train['teacher_prefix'],\n",
    "        \"project_grade_category\":X_train['project_grade_category'], \"total_text\":X_train['total_text'],\n",
    "        \"clean_categories\":X_train['clean_categories'], \"clean_subcategories\":X_train['clean_subcategories']}\n",
    "              ,{\n",
    "              \"final_output\":X_train['output']},\n",
    "                 batch_size=2500,\n",
    "                 epochs=40,\n",
    "              \n",
    "              validation_data=({\"posted_projects\":X_test['posted_projects'], \"price\":X_test['price'],\n",
    "              \"Is_digit_present\":X_test['Is_digit_present'], \"quantity\":X_test['quantity'],\n",
    "              \"school_state\":X_test['school_state'], \"teacher_prefix\":X_test['teacher_prefix'],\n",
    "        \"project_grade_category\":X_test['project_grade_category'], \"total_text\":X_test['total_text'],\n",
    "        \"clean_categories\":X_test['clean_categories'], \"clean_subcategories\":X_test['clean_subcategories']}\n",
    "              ,{\n",
    "              \"final_output\":X_test['output']}),\n",
    "                callbacks=[tb])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving my neural network model to JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import model_from_json\n",
    "\n",
    "# serialize model to JSON\n",
    "model_json = model.to_json()\n",
    "with open(\"model.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "# serialize weights to HDF5\n",
    "model.save_weights(\"model.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting TF-IDF values of words in text data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "# merge texts\n",
    "text = list(train['total_text']) \n",
    "\n",
    "tfidf = TfidfVectorizer()\n",
    "tfidf.fit_transform(text)\n",
    "\n",
    "# dict key:word and value:tf-idf score\n",
    "word2tfidf = dict(zip(tfidf.get_feature_names(), tfidf.idf_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "score=[]\n",
    "for key in word2tfidf.keys():\n",
    "    score.append(word2tfidf[key])\n",
    "score=np.asarray(score).reshape(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.boxplot([score])\n",
    "plt.title('TF-IDF score')\n",
    "plt.xlabel('data points')\n",
    "plt.ylabel('score')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### based on the above box plot low tf-idf value is 10 and high tf-idf value is 12"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Removing words which have very high or very low TF-IDF values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_words=[]\n",
    "for i in range(109248):\n",
    "    total_words=(data['total_text'][i])\n",
    "    wordList = re.sub(\"[^\\w]\", \" \",  total_words).split()\n",
    "    for j in wordList:\n",
    "        try:\n",
    "            idf = word2tfidf[j]\n",
    "        except:\n",
    "            idf = 0\n",
    "        if(idf>10 and idf <12):\n",
    "            continue;\n",
    "        else:\n",
    "            remove_words.append(j)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_words=list(set(remove_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#code copied from ---https://stackoverflow.com/questions/45447848/check-for-words-from-list-and-remove-those-words-in-pandas-dataframe-column\n",
    "remove= r'\\b(?:{})\\b'.format('|'.join(remove_words))\n",
    "train['total_text'] = train['total_text'].str.replace(remove, '')\n",
    "test['total_text'] = test['total_text'].str.replace(remove, '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "token = Tokenizer()\n",
    "\n",
    "token.fit_on_texts(train['total_text'])\n",
    "train['total_text']=token.texts_to_sequences(train['total_text'])\n",
    "test['total_text']=token.texts_to_sequences(test['total_text'])\n",
    "text_size = len(token.word_index) + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting data in the form of Dictionary which then will be given as a input to Deep Learning Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train={}\n",
    "\n",
    "X_train[\"posted_projects\"]= array(train[\"teacher_number_of_previously_posted_projects\"]).reshape(len(train),1)\n",
    "X_train[\"price\"]= array(train[\"price\"]).reshape(len(train),1)\n",
    "X_train[\"quantity\"]= array(train[\"quantity\"]).reshape(len(train),1)\n",
    "X_train[\"Is_digit_present\"]= array(train[\"Is_digit_present\"]).reshape(len(train),1)\n",
    "        \n",
    "X_train[\"teacher_prefix\"]= pad_sequences(train[\"teacher_prefix\"], maxlen=1)\n",
    "X_train[\"school_state\"]= pad_sequences(train[\"school_state\"], maxlen=1)\n",
    "X_train[\"project_grade_category\"]= pad_sequences(train[\"project_grade_category\"], maxlen=3)\n",
    "        \n",
    "X_train[\"total_text\"]= pad_sequences(train[\"total_text\"], maxlen=300)\n",
    "X_train[\"clean_categories\"]= pad_sequences(train[\"clean_categories\"], maxlen=4)\n",
    "X_train[\"clean_subcategories\"]= pad_sequences(train[\"clean_subcategories\"], maxlen=4)\n",
    "\n",
    "X_train[\"output\"]= array(train[\"project_is_approved\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test={}\n",
    "\n",
    "X_test[\"posted_projects\"]= array(test[\"teacher_number_of_previously_posted_projects\"]).reshape(len(test),1)\n",
    "X_test[\"price\"]= array(test[\"price\"]).reshape(len(test),1)\n",
    "X_test[\"quantity\"]= array(test[\"quantity\"]).reshape(len(test),1)\n",
    "X_test[\"Is_digit_present\"]= array(test[\"Is_digit_present\"]).reshape(len(test),1)\n",
    "        \n",
    "X_test[\"teacher_prefix\"]= pad_sequences(test[\"teacher_prefix\"], maxlen=1)\n",
    "X_test[\"school_state\"]= pad_sequences(test[\"school_state\"], maxlen=1)\n",
    "X_test[\"project_grade_category\"]= pad_sequences(test[\"project_grade_category\"], maxlen=3)\n",
    "        \n",
    "X_test[\"total_text\"]= pad_sequences(test[\"total_text\"], maxlen=300)\n",
    "X_test[\"clean_categories\"]= pad_sequences(test[\"clean_categories\"], maxlen=4)\n",
    "X_test[\"clean_subcategories\"]= pad_sequences(test[\"clean_subcategories\"], maxlen=4)\n",
    "\n",
    "X_test[\"output\"]= array(test[\"project_is_approved\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "total_text (InputLayer)         (None, 300)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "posted_projects (InputLayer)    (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "price (InputLayer)              (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "Is_digit_present (InputLayer)   (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "quantity (InputLayer)           (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_7 (Embedding)         (None, 300, 300)     18616800    total_text[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "clean_categories (InputLayer)   (None, 4)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "clean_subcategories (InputLayer (None, 4)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "school_state (InputLayer)       (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "teacher_prefix (InputLayer)     (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "project_grade_category (InputLa (None, 3)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 4)            0           posted_projects[0][0]            \n",
      "                                                                 price[0][0]                      \n",
      "                                                                 Is_digit_present[0][0]           \n",
      "                                                                 quantity[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lstm_2 (LSTM)                   (None, 300, 12)      15024       embedding_7[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "embedding_8 (Embedding)         (None, 4, 4)         64          clean_categories[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "embedding_9 (Embedding)         (None, 4, 4)         152         clean_subcategories[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "embedding_10 (Embedding)        (None, 1, 8)         416         school_state[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "embedding_11 (Embedding)        (None, 1, 2)         12          teacher_prefix[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "embedding_12 (Embedding)        (None, 3, 2)         20          project_grade_category[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 4)            20          concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten_3 (Flatten)             (None, 3600)         0           lstm_2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "flatten_4 (Flatten)             (None, 16)           0           embedding_8[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "flatten_5 (Flatten)             (None, 16)           0           embedding_9[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "flatten_6 (Flatten)             (None, 8)            0           embedding_10[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "flatten_7 (Flatten)             (None, 2)            0           embedding_11[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "flatten_8 (Flatten)             (None, 6)            0           embedding_12[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 3652)         0           dense_1[0][0]                    \n",
      "                                                                 flatten_3[0][0]                  \n",
      "                                                                 flatten_4[0][0]                  \n",
      "                                                                 flatten_5[0][0]                  \n",
      "                                                                 flatten_6[0][0]                  \n",
      "                                                                 flatten_7[0][0]                  \n",
      "                                                                 flatten_8[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 8)            29224       concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 8)            32          dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 4)            36          batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 2)            10          dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "final_output (Dense)            (None, 1)            3           dense_4[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 18,661,813\n",
      "Trainable params: 44,997\n",
      "Non-trainable params: 18,616,816\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "    # Input layers\n",
    "previously_posted_projects = Input(shape=(1,), name=\"posted_projects\")\n",
    "price = Input(shape=(1,), name=\"price\")\n",
    "digit_present = Input(shape=(1,), name=\"Is_digit_present\")\n",
    "quantity = Input(shape=(1,), name=\"quantity\")\n",
    "    \n",
    "    \n",
    "school_state = Input(shape=(1,), name=\"school_state\")\n",
    "teacher_prefix = Input(shape=(1,), name=\"teacher_prefix\")\n",
    "project_grade= Input(shape=(3,), name=\"project_grade_category\")\n",
    "    \n",
    "total_text = Input(shape=(300,), name=\"total_text\")\n",
    "clean_categories = Input(shape=(4,), name=\"clean_categories\")\n",
    "clean_subcategories = Input(shape=(4,), name=\"clean_subcategories\")\n",
    "    \n",
    "    # Batch normalization layer\n",
    "#previously_posted_projects_bn = BatchNormalization(axis=1, momentum=0.99, epsilon=0.001, center=True, scale=True, beta_initializer='zeros', gamma_initializer='ones', moving_mean_initializer='zeros', moving_variance_initializer='ones')(previously_posted_projects)\n",
    "#price_bn = BatchNormalization(axis=1, momentum=0.99, epsilon=0.001, center=True, scale=True, beta_initializer='zeros', gamma_initializer='ones', moving_mean_initializer='zeros', moving_variance_initializer='ones')(price)\n",
    "#quantity_bn = BatchNormalization(axis=1, momentum=0.99, epsilon=0.001, center=True, scale=True, beta_initializer='zeros', gamma_initializer='ones', moving_mean_initializer='zeros', moving_variance_initializer='ones')(quantity)\n",
    "    \n",
    "    \n",
    "    \n",
    "    # Embedding layers\n",
    "emb_text_layer = Embedding(text_size, 300, weights=[embedding_matrix],  trainable=False)\n",
    "emb_category_layer = Embedding(category_size, 4)\n",
    "emb_subcategory_layer = Embedding(subcategory_size, 4)\n",
    "    \n",
    "emb_state_layer = Embedding(state_size, 8)\n",
    "emb_prefix_layer = Embedding(prefix_size, 2)\n",
    "emb_grade_layer = Embedding(grade_size, 2)\n",
    "    \n",
    "    # Giving Input to Embedding layers\n",
    "emb_text = emb_text_layer(total_text)\n",
    "emb_category =emb_category_layer(clean_categories)\n",
    "emb_subcategory =emb_subcategory_layer(clean_subcategories)\n",
    "    \n",
    "emb_state =emb_state_layer(school_state)\n",
    "emb_prefix =emb_prefix_layer(teacher_prefix)\n",
    "emb_grade =emb_grade_layer(project_grade)\n",
    "    \n",
    "        \n",
    "    # LSTM layers\n",
    "lstm_text = LSTM(12, activation=\"relu\", return_sequences=True)(emb_text)\n",
    "    \n",
    "    # Flatten layers\n",
    "flatten_text =Flatten()(lstm_text)\n",
    "flatten_category =Flatten()(emb_category)\n",
    "flatten_subcategory =keras.layers.Flatten()(emb_subcategory)\n",
    "    \n",
    "flatten_state =Flatten()(emb_state)\n",
    "flatten_prefix =Flatten()(emb_prefix)\n",
    "flatten_grade =Flatten()(emb_grade)\n",
    "    \n",
    "    # concatenation of all numeric layers\n",
    "numeric= concatenate([previously_posted_projects,\n",
    "                                      price,\n",
    "                                      digit_present,\n",
    "                                      quantity])\n",
    "    # Dense layer\n",
    "dense_numeric =Dense(4, activation='relu',kernel_initializer=he_normal(seed=5))(numeric)\n",
    "    \n",
    "    # Merge all layers into one\n",
    "x = concatenate([dense_numeric,\n",
    "                                 flatten_text,\n",
    "                                 flatten_category,\n",
    "                                 flatten_subcategory,\n",
    "                                 flatten_state,\n",
    "                                 flatten_prefix,\n",
    "                                 flatten_grade])\n",
    "    \n",
    "dense_x =Dense(8, activation='relu',kernel_initializer=he_normal(seed=3))(x)\n",
    "    \n",
    "dense_x_bn= BatchNormalization(axis=1, momentum=0.99, epsilon=0.001, center=True, scale=True, beta_initializer='zeros', gamma_initializer='ones', moving_mean_initializer='zeros', moving_variance_initializer='ones')(dense_x)\n",
    "    \n",
    "#drop_x =Dropout(0.5)(dense_x_bn)\n",
    "    \n",
    "dense2_x =Dense(4, activation='relu',kernel_initializer=he_normal(seed=1))(dense_x_bn)\n",
    "    \n",
    "#drop2_x =Dropout(0.5)(dense2_x)\n",
    "    \n",
    "dense3_x =Dense(2, activation='relu',kernel_initializer=he_normal(seed=2))(dense2_x)\n",
    "    \n",
    "    # Dense layers\n",
    "    #x = keras.layers.Dense(128, activation=\"relu\")(x)\n",
    "\n",
    "    # Output layers\n",
    "output = Dense(1, activation=\"sigmoid\", name='final_output')(dense3_x)\n",
    "    \n",
    "\n",
    "\n",
    "model = Model(inputs=[previously_posted_projects,price,digit_present,quantity,school_state,teacher_prefix,project_grade,total_text,clean_categories,clean_subcategories], outputs=[output])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running Model 1 but with words removed based on their TF-IDF values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\metrics_impl.py:526: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\metrics_impl.py:788: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Deprecated in favor of operator or tf.math.divide.\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 98323 samples, validate on 10925 samples\n",
      "Epoch 1/40\n",
      "98323/98323 [==============================] - 36s 362us/step - loss: 0.6599 - roc_auc: 0.4565 - val_loss: 0.6201 - val_roc_auc: 0.4675\n",
      "Epoch 2/40\n",
      "98323/98323 [==============================] - 33s 333us/step - loss: 0.5860 - roc_auc: 0.4874 - val_loss: 0.5089 - val_roc_auc: 0.5061\n",
      "Epoch 3/40\n",
      "98323/98323 [==============================] - 33s 337us/step - loss: 0.5117 - roc_auc: 0.5199 - val_loss: 0.4726 - val_roc_auc: 0.5307\n",
      "Epoch 4/40\n",
      "98323/98323 [==============================] - 33s 336us/step - loss: 0.4589 - roc_auc: 0.5406 - val_loss: 0.4307 - val_roc_auc: 0.5484\n",
      "Epoch 5/40\n",
      "98323/98323 [==============================] - 33s 335us/step - loss: 0.4236 - roc_auc: 0.5563 - val_loss: 0.4505 - val_roc_auc: 0.5630\n",
      "Epoch 6/40\n",
      "98323/98323 [==============================] - 33s 332us/step - loss: 0.4017 - roc_auc: 0.5702 - val_loss: 0.4707 - val_roc_auc: 0.5766\n",
      "Epoch 7/40\n",
      "98323/98323 [==============================] - 33s 335us/step - loss: 0.3895 - roc_auc: 0.5835 - val_loss: 0.4460 - val_roc_auc: 0.5899\n",
      "Epoch 8/40\n",
      "98323/98323 [==============================] - 33s 333us/step - loss: 0.3817 - roc_auc: 0.5967 - val_loss: 0.4476 - val_roc_auc: 0.6026\n",
      "Epoch 9/40\n",
      "98323/98323 [==============================] - 33s 338us/step - loss: 0.3781 - roc_auc: 0.6085 - val_loss: 0.4495 - val_roc_auc: 0.6137\n",
      "Epoch 10/40\n",
      "98323/98323 [==============================] - 33s 338us/step - loss: 0.3729 - roc_auc: 0.6191 - val_loss: 0.4454 - val_roc_auc: 0.6238\n",
      "Epoch 11/40\n",
      "98323/98323 [==============================] - 33s 336us/step - loss: 0.3688 - roc_auc: 0.6287 - val_loss: 0.4161 - val_roc_auc: 0.6334\n",
      "Epoch 12/40\n",
      "98323/98323 [==============================] - 34s 344us/step - loss: 0.3661 - roc_auc: 0.6383 - val_loss: 0.4534 - val_roc_auc: 0.6421\n",
      "Epoch 13/40\n",
      "98323/98323 [==============================] - 33s 341us/step - loss: 0.3627 - roc_auc: 0.6461 - val_loss: 0.4164 - val_roc_auc: 0.6499\n",
      "Epoch 14/40\n",
      "98323/98323 [==============================] - 33s 333us/step - loss: 0.3596 - roc_auc: 0.6540 - val_loss: 0.4248 - val_roc_auc: 0.6575\n",
      "Epoch 15/40\n",
      "98323/98323 [==============================] - 33s 336us/step - loss: 0.3567 - roc_auc: 0.6612 - val_loss: 0.4345 - val_roc_auc: 0.6643\n",
      "Epoch 16/40\n",
      "98323/98323 [==============================] - 33s 331us/step - loss: 0.3539 - roc_auc: 0.6676 - val_loss: 0.4643 - val_roc_auc: 0.6705\n",
      "Epoch 17/40\n",
      "98323/98323 [==============================] - 33s 335us/step - loss: 0.3529 - roc_auc: 0.6733 - val_loss: 0.4027 - val_roc_auc: 0.6763\n",
      "Epoch 18/40\n",
      "98323/98323 [==============================] - 32s 329us/step - loss: 0.3489 - roc_auc: 0.6795 - val_loss: 0.4042 - val_roc_auc: 0.6824\n",
      "Epoch 19/40\n",
      "98323/98323 [==============================] - 33s 334us/step - loss: 0.3462 - roc_auc: 0.6854 - val_loss: 0.4231 - val_roc_auc: 0.6879\n",
      "Epoch 20/40\n",
      "98323/98323 [==============================] - 33s 336us/step - loss: 0.3442 - roc_auc: 0.6906 - val_loss: 0.4086 - val_roc_auc: 0.6931\n",
      "Epoch 21/40\n",
      "98323/98323 [==============================] - 33s 333us/step - loss: 0.3409 - roc_auc: 0.6957 - val_loss: 0.4063 - val_roc_auc: 0.6981\n",
      "Epoch 22/40\n",
      "98323/98323 [==============================] - 33s 336us/step - loss: 0.3383 - roc_auc: 0.7006 - val_loss: 0.4158 - val_roc_auc: 0.7029\n",
      "Epoch 23/40\n",
      "98323/98323 [==============================] - 33s 336us/step - loss: 0.3356 - roc_auc: 0.7054 - val_loss: 0.4091 - val_roc_auc: 0.7075\n",
      "Epoch 24/40\n",
      "98323/98323 [==============================] - 33s 335us/step - loss: 0.3333 - roc_auc: 0.7098 - val_loss: 0.4304 - val_roc_auc: 0.7118\n",
      "Epoch 25/40\n",
      "98323/98323 [==============================] - 33s 337us/step - loss: 0.3309 - roc_auc: 0.7140 - val_loss: 0.4497 - val_roc_auc: 0.7158\n",
      "Epoch 26/40\n",
      "98323/98323 [==============================] - 33s 333us/step - loss: 0.3286 - roc_auc: 0.7178 - val_loss: 0.4439 - val_roc_auc: 0.7196\n",
      "Epoch 27/40\n",
      "98323/98323 [==============================] - 33s 334us/step - loss: 0.3259 - roc_auc: 0.7216 - val_loss: 0.4760 - val_roc_auc: 0.7232\n",
      "Epoch 28/40\n",
      "98323/98323 [==============================] - 33s 333us/step - loss: 0.3231 - roc_auc: 0.7251 - val_loss: 0.5100 - val_roc_auc: 0.7266\n",
      "Epoch 29/40\n",
      "98323/98323 [==============================] - 33s 331us/step - loss: 0.3220 - roc_auc: 0.7284 - val_loss: 0.4288 - val_roc_auc: 0.7301\n",
      "Epoch 30/40\n",
      "98323/98323 [==============================] - 33s 333us/step - loss: 0.3187 - roc_auc: 0.7319 - val_loss: 0.4312 - val_roc_auc: 0.7336\n",
      "Epoch 31/40\n",
      "98323/98323 [==============================] - 34s 351us/step - loss: 0.3149 - roc_auc: 0.7354 - val_loss: 0.4542 - val_roc_auc: 0.7369\n",
      "Epoch 32/40\n",
      "98323/98323 [==============================] - 33s 334us/step - loss: 0.3138 - roc_auc: 0.7386 - val_loss: 0.4366 - val_roc_auc: 0.7402\n",
      "Epoch 33/40\n",
      "98323/98323 [==============================] - 33s 334us/step - loss: 0.3122 - roc_auc: 0.7419 - val_loss: 0.4799 - val_roc_auc: 0.7433\n",
      "Epoch 34/40\n",
      "98323/98323 [==============================] - 33s 334us/step - loss: 0.3110 - roc_auc: 0.7448 - val_loss: 0.5137 - val_roc_auc: 0.7460\n",
      "Epoch 35/40\n",
      "98323/98323 [==============================] - 33s 334us/step - loss: 0.3075 - roc_auc: 0.7474 - val_loss: 0.5957 - val_roc_auc: 0.7483\n",
      "Epoch 36/40\n",
      "98323/98323 [==============================] - 33s 340us/step - loss: 0.3051 - roc_auc: 0.7496 - val_loss: 0.5717 - val_roc_auc: 0.7505\n",
      "Epoch 37/40\n",
      "98323/98323 [==============================] - 33s 335us/step - loss: 0.3031 - roc_auc: 0.7518 - val_loss: 0.4656 - val_roc_auc: 0.7531\n",
      "Epoch 38/40\n",
      "98323/98323 [==============================] - 33s 336us/step - loss: 0.3026 - roc_auc: 0.7545 - val_loss: 0.4533 - val_roc_auc: 0.7558\n",
      "Epoch 39/40\n",
      "98323/98323 [==============================] - 33s 336us/step - loss: 0.3004 - roc_auc: 0.7572 - val_loss: 0.4777 - val_roc_auc: 0.7585\n",
      "Epoch 40/40\n",
      "98323/98323 [==============================] - 33s 337us/step - loss: 0.2981 - roc_auc: 0.7599 - val_loss: 0.4897 - val_roc_auc: 0.7610\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2172b500f60>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "tb =TensorBoard(log_dir=\"logs2/{}\".format(time()))\n",
    "\n",
    "model.compile(optimizer = Adam(lr=1e-3),\n",
    "                  loss={'final_output': 'binary_crossentropy'},\n",
    "                  metrics=[roc_auc])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "model.fit({\"posted_projects\":X_train['posted_projects'], \"price\":X_train['price'],\n",
    "              \"Is_digit_present\":X_train['Is_digit_present'], \"quantity\":X_train['quantity'],\n",
    "              \"school_state\":X_train['school_state'], \"teacher_prefix\":X_train['teacher_prefix'],\n",
    "        \"project_grade_category\":X_train['project_grade_category'], \"total_text\":X_train['total_text'],\n",
    "        \"clean_categories\":X_train['clean_categories'], \"clean_subcategories\":X_train['clean_subcategories']}\n",
    "              ,{\n",
    "              \"final_output\":X_train['output']},\n",
    "                 batch_size=2500,\n",
    "                epochs=40,\n",
    "              \n",
    "               validation_data=({\"posted_projects\":X_test['posted_projects'], \"price\":X_test['price'],\n",
    "              \"Is_digit_present\":X_test['Is_digit_present'], \"quantity\":X_test['quantity'],\n",
    "              \"school_state\":X_test['school_state'], \"teacher_prefix\":X_test['teacher_prefix'],\n",
    "        \"project_grade_category\":X_test['project_grade_category'], \"total_text\":X_test['total_text'],\n",
    "        \"clean_categories\":X_test['clean_categories'], \"clean_subcategories\":X_test['clean_subcategories']}\n",
    "              ,{\n",
    "              \"final_output\":X_test['output']}),\n",
    "                callbacks=[tb])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving my neural network model to JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# serialize model to JSON\n",
    "model_json = model.to_json()\n",
    "with open(\"model_reduce_words.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "# serialize weights to HDF5\n",
    "model.save_weights(\"model_reduce_words.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One Hot encoding categorical data using keras preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['teacher_prefix'] = train['teacher_prefix'].map(lambda a:keras.preprocessing.text.one_hot(a,100))\n",
    "train['school_state'] = train['school_state'].map(lambda a:keras.preprocessing.text.one_hot(a,100))\n",
    "train['project_grade_category'] = train['project_grade_category'].map(lambda a:keras.preprocessing.text.one_hot(a,100))\n",
    "train['clean_categories'] = train['clean_categories'].map(lambda a:keras.preprocessing.text.one_hot(a,100))\n",
    "train['clean_subcategories'] = train['clean_subcategories'].map(lambda a:keras.preprocessing.text.one_hot(a,100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['teacher_prefix'] = test['teacher_prefix'].map(lambda a:keras.preprocessing.text.one_hot(a,100))\n",
    "test['school_state'] = test['school_state'].map(lambda a:keras.preprocessing.text.one_hot(a,100))\n",
    "test['project_grade_category'] = test['project_grade_category'].map(lambda a:keras.preprocessing.text.one_hot(a,100))\n",
    "test['clean_categories'] = test['clean_categories'].map(lambda a:keras.preprocessing.text.one_hot(a,100))\n",
    "test['clean_subcategories'] = test['clean_subcategories'].map(lambda a:keras.preprocessing.text.one_hot(a,100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting data in the form of Dictionary which then will be given as a input to Deep Learning Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train={} \n",
    "\n",
    "X_train[\"posted_projects\"]= array(train[\"teacher_number_of_previously_posted_projects\"]).reshape(len(train),1)\n",
    "X_train[\"price\"]= array(train[\"price\"]).reshape(len(train),1)\n",
    "X_train[\"quantity\"]= array(train[\"quantity\"]).reshape(len(train),1)\n",
    "X_train[\"Is_digit_present\"]= array(train[\"Is_digit_present\"]).reshape(len(train),1)\n",
    "        \n",
    "X_train[\"teacher_prefix\"]= pad_sequences(train[\"teacher_prefix\"], maxlen=4)\n",
    "X_train[\"school_state\"]= pad_sequences(train[\"school_state\"], maxlen=4)\n",
    "X_train[\"project_grade_category\"]= pad_sequences(train[\"project_grade_category\"], maxlen=4)\n",
    "        \n",
    "X_train[\"total_text\"]= pad_sequences(train[\"total_text\"], maxlen=300)\n",
    "X_train[\"clean_categories\"]= pad_sequences(train[\"clean_categories\"], maxlen=4)\n",
    "X_train[\"clean_subcategories\"]= pad_sequences(train[\"clean_subcategories\"], maxlen=4)\n",
    "\n",
    "X_train[\"output\"]= array(train[\"project_is_approved\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test={}\n",
    "\n",
    "X_test[\"posted_projects\"]= array(test[\"teacher_number_of_previously_posted_projects\"]).reshape(len(test),1)\n",
    "X_test[\"price\"]= array(test[\"price\"]).reshape(len(test),1)\n",
    "X_test[\"quantity\"]= array(test[\"quantity\"]).reshape(len(test),1)\n",
    "X_test[\"Is_digit_present\"]= array(test[\"Is_digit_present\"]).reshape(len(test),1)\n",
    "        \n",
    "X_test[\"teacher_prefix\"]= pad_sequences(test[\"teacher_prefix\"], maxlen=4)\n",
    "X_test[\"school_state\"]= pad_sequences(test[\"school_state\"], maxlen=4)\n",
    "X_test[\"project_grade_category\"]= pad_sequences(test[\"project_grade_category\"], maxlen=4)\n",
    "        \n",
    "X_test[\"total_text\"]= pad_sequences(test[\"total_text\"], maxlen=300)\n",
    "X_test[\"clean_categories\"]= pad_sequences(test[\"clean_categories\"], maxlen=4)\n",
    "X_test[\"clean_subcategories\"]= pad_sequences(test[\"clean_subcategories\"], maxlen=4)\n",
    "\n",
    "X_test[\"output\"]= array(test[\"project_is_approved\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers.core import Reshape\n",
    "from keras.layers import Conv1D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "school_state (InputLayer)       (None, 4)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "teacher_prefix (InputLayer)     (None, 4)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "project_grade_category (InputLa (None, 4)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "clean_categories (InputLayer)   (None, 4)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "clean_subcategories (InputLayer (None, 4)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_13 (Concatenate)    (None, 20)           0           school_state[0][0]               \n",
      "                                                                 teacher_prefix[0][0]             \n",
      "                                                                 project_grade_category[0][0]     \n",
      "                                                                 clean_categories[0][0]           \n",
      "                                                                 clean_subcategories[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "total_text (InputLayer)         (None, 300)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "reshape_7 (Reshape)             (None, 4, 5)         0           concatenate_13[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "embedding_7 (Embedding)         (None, 300, 300)     18616800    total_text[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_13 (Conv1D)              (None, 4, 12)        72          reshape_7[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lstm_7 (LSTM)                   (None, 300, 14)      17640       embedding_7[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_14 (Conv1D)              (None, 2, 24)        888         conv1d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "flatten_13 (Flatten)            (None, 4200)         0           lstm_7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "flatten_14 (Flatten)            (None, 48)           0           conv1d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "posted_projects (InputLayer)    (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "price (InputLayer)              (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "quantity (InputLayer)           (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "Is_digit_present (InputLayer)   (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_14 (Concatenate)    (None, 4252)         0           flatten_13[0][0]                 \n",
      "                                                                 flatten_14[0][0]                 \n",
      "                                                                 posted_projects[0][0]            \n",
      "                                                                 price[0][0]                      \n",
      "                                                                 quantity[0][0]                   \n",
      "                                                                 Is_digit_present[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dense_17 (Dense)                (None, 8)            34024       concatenate_14[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 8)            32          dense_17[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_18 (Dense)                (None, 4)            36          batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dense_19 (Dense)                (None, 2)            10          dense_18[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "final_output (Dense)            (None, 1)            3           dense_19[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 18,669,505\n",
      "Trainable params: 52,689\n",
      "Non-trainable params: 18,616,816\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "    # Input layers\n",
    "previously_posted_projects = Input(shape=(1,), name=\"posted_projects\")\n",
    "price = Input(shape=(1,), name=\"price\")\n",
    "digit_present = Input(shape=(1,), name=\"Is_digit_present\")\n",
    "quantity = Input(shape=(1,), name=\"quantity\")\n",
    "    \n",
    "    \n",
    "school_state = Input(shape=(4,), name=\"school_state\")\n",
    "teacher_prefix = Input(shape=(4,), name=\"teacher_prefix\")\n",
    "project_grade= Input(shape=(4,), name=\"project_grade_category\")\n",
    "    \n",
    "total_text = Input(shape=(300,), name=\"total_text\")\n",
    "clean_categories = Input(shape=(4,), name=\"clean_categories\")\n",
    "clean_subcategories = Input(shape=(4,), name=\"clean_subcategories\")\n",
    "       \n",
    "    # Embedding layers\n",
    "emb_text_layer = Embedding(text_size, 300, weights=[embedding_matrix], trainable=False)\n",
    "    \n",
    "    \n",
    "    # Giving Input to Embedding layers\n",
    "emb_text = emb_text_layer(total_text)\n",
    "            \n",
    "    # LSTM layers\n",
    "lstm_text = LSTM(14, activation=\"relu\", return_sequences=True)(emb_text)\n",
    "    \n",
    "    # Flatten layers\n",
    "flatten_text = Flatten()(lstm_text)\n",
    "    \n",
    "    \n",
    "    # concatenation of all numeric and categorical layers\n",
    "other= concatenate([ \n",
    "                                      school_state,\n",
    "                                      teacher_prefix,\n",
    "                                      project_grade,\n",
    "                                      clean_categories,\n",
    "                                      clean_subcategories])\n",
    "    # Dense layer\n",
    "new= Reshape([4,-1])(other)\n",
    "    \n",
    "    # cnn layer\n",
    "cnn_1= Conv1D(12,1, activation='relu')(new)\n",
    "    \n",
    "cnn_2= Conv1D(24, 3, activation='relu')(cnn_1)\n",
    "    \n",
    "    # Flatten layer\n",
    "flatten_cnn_2= Flatten()(cnn_2)\n",
    "    \n",
    "     # Batch normalization layer\n",
    "#previously_posted_projects_bn = BatchNormalization(axis=1, momentum=0.99, epsilon=0.001, center=True, scale=True, beta_initializer='zeros', gamma_initializer='ones', moving_mean_initializer='zeros', moving_variance_initializer='ones')(previously_posted_projects)\n",
    "#price_bn= BatchNormalization(axis=1, momentum=0.99, epsilon=0.001, center=True, scale=True, beta_initializer='zeros', gamma_initializer='ones', moving_mean_initializer='zeros', moving_variance_initializer='ones')(price)\n",
    "#quantity_bn = BatchNormalization(axis=1, momentum=0.99, epsilon=0.001, center=True, scale=True, beta_initializer='zeros', gamma_initializer='ones', moving_mean_initializer='zeros', moving_variance_initializer='ones')(quantity)\n",
    "    \n",
    "    \n",
    "    # Merge all layers into one\n",
    "x = concatenate([flatten_text, flatten_cnn_2,previously_posted_projects,\n",
    "                                 price,\n",
    "                                 quantity,\n",
    "                                 digit_present])\n",
    "    \n",
    "dense_x = Dense(8, activation='relu',kernel_initializer=he_normal(seed=None))(x)\n",
    "    \n",
    "dense_x_bn= keras.layers.BatchNormalization(axis=1, momentum=0.99, epsilon=0.001, center=True, scale=True, beta_initializer='zeros', gamma_initializer='ones', moving_mean_initializer='zeros', moving_variance_initializer='ones')(dense_x)\n",
    "    \n",
    "#drop_x = Dropout(0.5)(dense_x_bn)\n",
    "    \n",
    "dense2_x = Dense(4, activation='relu',kernel_initializer=he_normal(seed=None))(dense_x_bn)\n",
    "    \n",
    "#drop2_x = Dropout(0.5)(dense2_x)\n",
    "    \n",
    "dense3_x = Dense(2, activation='relu',kernel_initializer=he_normal(seed=None))(dense2_x)\n",
    "    \n",
    "    # Dense layers\n",
    "    #x = keras.layers.Dense(128, activation=\"relu\")(x)\n",
    "\n",
    "    # Output layers\n",
    "output = Dense(1, activation=\"sigmoid\", name=\"final_output\")(dense3_x)\n",
    "    \n",
    "\n",
    "\n",
    "model = Model(inputs=[previously_posted_projects,price,digit_present,quantity,school_state,teacher_prefix,project_grade,total_text,clean_categories,clean_subcategories], outputs=[output])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 98323 samples, validate on 10925 samples\n",
      "Epoch 1/40\n",
      "98323/98323 [==============================] - 36s 371us/step - loss: 0.4426 - roc_auc: 0.5899 - val_loss: 0.4213 - val_roc_auc: 0.6301\n",
      "Epoch 2/40\n",
      "98323/98323 [==============================] - 34s 341us/step - loss: 0.3742 - roc_auc: 0.6606 - val_loss: 0.3895 - val_roc_auc: 0.6835\n",
      "Epoch 3/40\n",
      "98323/98323 [==============================] - 34s 341us/step - loss: 0.3647 - roc_auc: 0.6986 - val_loss: 0.3843 - val_roc_auc: 0.7091\n",
      "Epoch 4/40\n",
      "98323/98323 [==============================] - 34s 342us/step - loss: 0.3570 - roc_auc: 0.7185 - val_loss: 0.4054 - val_roc_auc: 0.7250\n",
      "Epoch 5/40\n",
      "98323/98323 [==============================] - 34s 342us/step - loss: 0.3504 - roc_auc: 0.7317 - val_loss: 0.3895 - val_roc_auc: 0.7371\n",
      "Epoch 6/40\n",
      "98323/98323 [==============================] - 34s 341us/step - loss: 0.3401 - roc_auc: 0.7435 - val_loss: 0.3904 - val_roc_auc: 0.7484\n",
      "Epoch 7/40\n",
      "98323/98323 [==============================] - 34s 341us/step - loss: 0.3321 - roc_auc: 0.7542 - val_loss: 0.4048 - val_roc_auc: 0.7582\n",
      "Epoch 8/40\n",
      "98323/98323 [==============================] - 34s 343us/step - loss: 0.3228 - roc_auc: 0.7634 - val_loss: 0.4067 - val_roc_auc: 0.7672\n",
      "Epoch 9/40\n",
      "98323/98323 [==============================] - 33s 338us/step - loss: 0.3134 - roc_auc: 0.7720 - val_loss: 0.4245 - val_roc_auc: 0.7758\n",
      "Epoch 10/40\n",
      "98323/98323 [==============================] - 34s 343us/step - loss: 0.3072 - roc_auc: 0.7803 - val_loss: 0.4499 - val_roc_auc: 0.7831\n",
      "Epoch 11/40\n",
      "98323/98323 [==============================] - 34s 341us/step - loss: 0.2974 - roc_auc: 0.7874 - val_loss: 0.4687 - val_roc_auc: 0.7901\n",
      "Epoch 12/40\n",
      "98323/98323 [==============================] - 34s 341us/step - loss: 0.2916 - roc_auc: 0.7939 - val_loss: 0.4538 - val_roc_auc: 0.7965\n",
      "Epoch 13/40\n",
      "98323/98323 [==============================] - 34s 347us/step - loss: 0.2845 - roc_auc: 0.8000 - val_loss: 0.4703 - val_roc_auc: 0.8026\n",
      "Epoch 14/40\n",
      "98323/98323 [==============================] - 33s 340us/step - loss: 0.2759 - roc_auc: 0.8060 - val_loss: 0.4887 - val_roc_auc: 0.8084\n",
      "Epoch 15/40\n",
      "98323/98323 [==============================] - 33s 338us/step - loss: 0.2727 - roc_auc: 0.8115 - val_loss: 0.4735 - val_roc_auc: 0.8136\n",
      "Epoch 16/40\n",
      "98323/98323 [==============================] - 34s 343us/step - loss: 0.2742 - roc_auc: 0.8160 - val_loss: 0.5081 - val_roc_auc: 0.8178\n",
      "Epoch 17/40\n",
      "98323/98323 [==============================] - 33s 338us/step - loss: 0.2595 - roc_auc: 0.8206 - val_loss: 0.5350 - val_roc_auc: 0.8225\n",
      "Epoch 18/40\n",
      "98323/98323 [==============================] - 34s 342us/step - loss: 0.2728 - roc_auc: 0.8244 - val_loss: 0.5052 - val_roc_auc: 0.8257\n",
      "Epoch 19/40\n",
      "98323/98323 [==============================] - 33s 339us/step - loss: 0.2589 - roc_auc: 0.8278 - val_loss: 0.5571 - val_roc_auc: 0.8293\n",
      "Epoch 20/40\n",
      "98323/98323 [==============================] - 33s 340us/step - loss: 0.2495 - roc_auc: 0.8315 - val_loss: 0.5349 - val_roc_auc: 0.8331\n",
      "Epoch 21/40\n",
      "98323/98323 [==============================] - 34s 343us/step - loss: 0.2441 - roc_auc: 0.8353 - val_loss: 0.5689 - val_roc_auc: 0.8368\n",
      "Epoch 22/40\n",
      "98323/98323 [==============================] - 33s 339us/step - loss: 0.2405 - roc_auc: 0.8387 - val_loss: 0.5986 - val_roc_auc: 0.8401\n",
      "Epoch 23/40\n",
      "98323/98323 [==============================] - 33s 340us/step - loss: 0.2348 - roc_auc: 0.8420 - val_loss: 0.6061 - val_roc_auc: 0.8433\n",
      "Epoch 24/40\n",
      "98323/98323 [==============================] - 34s 341us/step - loss: 0.2321 - roc_auc: 0.8450 - val_loss: 0.5913 - val_roc_auc: 0.8463\n",
      "Epoch 25/40\n",
      "98323/98323 [==============================] - 34s 342us/step - loss: 0.2262 - roc_auc: 0.8480 - val_loss: 0.6160 - val_roc_auc: 0.8493\n",
      "Epoch 26/40\n",
      "98323/98323 [==============================] - 34s 343us/step - loss: 0.2252 - roc_auc: 0.8509 - val_loss: 0.6249 - val_roc_auc: 0.8520\n",
      "Epoch 27/40\n",
      "98323/98323 [==============================] - 34s 343us/step - loss: 0.2178 - roc_auc: 0.8536 - val_loss: 0.6534 - val_roc_auc: 0.8547\n",
      "Epoch 28/40\n",
      "98323/98323 [==============================] - 33s 340us/step - loss: 0.2179 - roc_auc: 0.8562 - val_loss: 0.6365 - val_roc_auc: 0.8572\n",
      "Epoch 29/40\n",
      "98323/98323 [==============================] - 33s 340us/step - loss: 0.2166 - roc_auc: 0.8586 - val_loss: 0.6717 - val_roc_auc: 0.8595\n",
      "Epoch 30/40\n",
      "98323/98323 [==============================] - 34s 341us/step - loss: 0.2143 - roc_auc: 0.8608 - val_loss: 0.6637 - val_roc_auc: 0.8617\n",
      "Epoch 31/40\n",
      "98323/98323 [==============================] - 34s 341us/step - loss: 0.2105 - roc_auc: 0.8629 - val_loss: 0.6719 - val_roc_auc: 0.8638\n",
      "Epoch 32/40\n",
      "98323/98323 [==============================] - 34s 344us/step - loss: 0.2097 - roc_auc: 0.8649 - val_loss: 0.6991 - val_roc_auc: 0.8657\n",
      "Epoch 33/40\n",
      "98323/98323 [==============================] - 34s 342us/step - loss: 0.2027 - roc_auc: 0.8669 - val_loss: 0.7001 - val_roc_auc: 0.8677\n",
      "Epoch 34/40\n",
      "98323/98323 [==============================] - 34s 342us/step - loss: 0.2018 - roc_auc: 0.8689 - val_loss: 0.6934 - val_roc_auc: 0.8696\n",
      "Epoch 35/40\n",
      "98323/98323 [==============================] - 34s 343us/step - loss: 0.2016 - roc_auc: 0.8706 - val_loss: 0.7564 - val_roc_auc: 0.8713\n",
      "Epoch 36/40\n",
      "98323/98323 [==============================] - 34s 343us/step - loss: 0.1961 - roc_auc: 0.8723 - val_loss: 0.7229 - val_roc_auc: 0.8730\n",
      "Epoch 37/40\n",
      "98323/98323 [==============================] - 33s 341us/step - loss: 0.2060 - roc_auc: 0.8739 - val_loss: 0.6924 - val_roc_auc: 0.8745\n",
      "Epoch 38/40\n",
      "98323/98323 [==============================] - 33s 340us/step - loss: 0.1971 - roc_auc: 0.8754 - val_loss: 0.6980 - val_roc_auc: 0.8760\n",
      "Epoch 39/40\n",
      "98323/98323 [==============================] - 33s 339us/step - loss: 0.1936 - roc_auc: 0.8769 - val_loss: 0.7701 - val_roc_auc: 0.8775\n",
      "Epoch 40/40\n",
      "98323/98323 [==============================] - 34s 343us/step - loss: 0.1885 - roc_auc: 0.8784 - val_loss: 0.7549 - val_roc_auc: 0.8790\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2bff0e0e710>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "tb =TensorBoard(log_dir=\"logs3/{}\".format(time()))\n",
    "\n",
    "model.compile(optimizer= Adam(lr=1e-2),\n",
    "                  loss={'final_output': 'binary_crossentropy'},\n",
    "                  metrics=[roc_auc])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "model.fit({\"posted_projects\":X_train['posted_projects'], \"price\":X_train['price'],\n",
    "              \"Is_digit_present\":X_train['Is_digit_present'], \"quantity\":X_train['quantity'],\n",
    "              \"school_state\":X_train['school_state'], \"teacher_prefix\":X_train['teacher_prefix'],\n",
    "        \"project_grade_category\":X_train['project_grade_category'], \"total_text\":X_train['total_text'],\n",
    "        \"clean_categories\":X_train['clean_categories'], \"clean_subcategories\":X_train['clean_subcategories']}\n",
    "              ,{\n",
    "              \"final_output\":X_train['output']},\n",
    "                 batch_size=2500,\n",
    "                epochs=40,\n",
    "              \n",
    "               validation_data=({\"posted_projects\":X_test['posted_projects'], \"price\":X_test['price'],\n",
    "              \"Is_digit_present\":X_test['Is_digit_present'], \"quantity\":X_test['quantity'],\n",
    "              \"school_state\":X_test['school_state'], \"teacher_prefix\":X_test['teacher_prefix'],\n",
    "        \"project_grade_category\":X_test['project_grade_category'], \"total_text\":X_test['total_text'],\n",
    "        \"clean_categories\":X_test['clean_categories'], \"clean_subcategories\":X_test['clean_subcategories']}\n",
    "              ,{\n",
    "              \"final_output\":X_test['output']}),\n",
    "                callbacks=[tb])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving my neural network model to JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# serialize model to JSON\n",
    "model_json = model.to_json()\n",
    "with open(\"model_conv1.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "# serialize weights to HDF5\n",
    "model.save_weights(\"model_conv1.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------------+-----------+----------+\n",
      "|         Model no.          | train auc | test auc |\n",
      "+----------------------------+-----------+----------+\n",
      "|          Model 1           |   0.7052  |  0.7055  |\n",
      "| Model 1 with reduced words |   0.7599  |  0.761   |\n",
      "|          Model 2           |   0.8784  |  0.879   |\n",
      "+----------------------------+-----------+----------+\n"
     ]
    }
   ],
   "source": [
    "#code copied from -http://zetcode.com/python/prettytable/\n",
    "from prettytable import PrettyTable   \n",
    "x = PrettyTable()\n",
    "x.field_names = [\"Model no.\", \"train auc\", \"test auc\"]\n",
    "x.add_row([\"Model 1\", 0.7052 ,0.7055])\n",
    "x.add_row([\"Model 1 with reduced words\", 0.7599, 0.7610])\n",
    "x.add_row([\"Model 2\", 0.8784 ,0.8790])\n",
    "\n",
    "print(x)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "LSTM_DonorChoose.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
