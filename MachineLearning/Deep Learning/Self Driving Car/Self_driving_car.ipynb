{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "XHFnthirwlfn"
   },
   "outputs": [],
   "source": [
    "# Credits: https://github.com/SullyChen/Autopilot-TensorFlow\n",
    "# Research paper: End to End Learning for Self-Driving Cars by Nvidia. [https://arxiv.org/pdf/1604.07316.pdf]\n",
    "\n",
    "# NVidia dataset: 72 hrs of video => 72*60*60*30 = 7,776,000 images\n",
    "# Nvidia blog: https://devblogs.nvidia.com/deep-learning-self-driving-cars/\n",
    "\n",
    "\n",
    "# Our Dataset: https://github.com/SullyChen/Autopilot-TensorFlow [https://drive.google.com/file/d/0B-KJCaaF7elleG1RbzVPZWV4Tlk/view]\n",
    "# Size: 25 minutes = 25*60*30 = 45,000 images ~ 2.3 GB\n",
    "\n",
    "\n",
    "# If you want to try on a slightly large dataset: 70 minutes of data ~ 223GB\n",
    "# Refer: https://medium.com/udacity/open-sourcing-223gb-of-mountain-view-driving-data-f6b5593fbfa5\n",
    "# Format: Image, latitude, longitude, gear, brake, throttle, steering angles and speed\n",
    "\n",
    "\n",
    "\n",
    "# Additional Installations:\n",
    "# pip3 install h5py\n",
    "\n",
    "\n",
    "# AWS: https://aws.amazon.com/blogs/machine-learning/get-started-with-deep-learning-using-the-aws-deep-learning-ami/\n",
    "\n",
    "# Youtube:https://www.youtube.com/watch?v=qhUvQiKec2U\n",
    "# Further reading and extensions: https://medium.com/udacity/teaching-a-machine-to-steer-a-car-d73217f2492c\n",
    "# More data: https://medium.com/udacity/open-sourcing-223gb-of-mountain-view-driving-data-f6b5593fbfa5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.misc\n",
    "import random\n",
    "\n",
    "xs = []\n",
    "ys = []\n",
    "\n",
    "#points to the end of the last batch\n",
    "train_batch_pointer = 0\n",
    "val_batch_pointer = 0\n",
    "\n",
    "#read data.txt\n",
    "with open(\"D:\\self car\\Autopilot-TensorFlow-master\\Autopilot-TensorFlow-master\\driving_dataset\\data.txt\") as f:\n",
    "    for line in f:\n",
    "        xs.append(\"D:\\self car\\Autopilot-TensorFlow-master\\Autopilot-TensorFlow-master\\driving_dataset/\" + line.split()[0])\n",
    "        #the paper by Nvidia uses the inverse of the turning radius,\n",
    "        #but steering wheel angle is proportional to the inverse of turning radius\n",
    "        #so the steering wheel angle in radians is used as the output\n",
    "        ys.append(float(line.split()[1]) * scipy.pi / 180)\n",
    "\n",
    "#get number of images\n",
    "num_images = len(xs)\n",
    "\n",
    "\n",
    "train_xs = xs[:int(len(xs) * 0.7)]\n",
    "train_ys = ys[:int(len(xs) * 0.7)]\n",
    "\n",
    "val_xs = xs[-int(len(xs) * 0.3):]\n",
    "val_ys = ys[-int(len(xs) * 0.3):]\n",
    "\n",
    "num_train_images = len(train_xs)\n",
    "num_val_images = len(val_xs)\n",
    "\n",
    "def LoadTrainBatch(batch_size):\n",
    "    global train_batch_pointer\n",
    "    x_out = []\n",
    "    y_out = []\n",
    "    for i in range(0, batch_size):\n",
    "        x_out.append(scipy.misc.imresize(scipy.misc.imread(train_xs[(train_batch_pointer + i) % num_train_images])[-150:], [66, 200]) / 255.0)\n",
    "        y_out.append([train_ys[(train_batch_pointer + i) % num_train_images]])\n",
    "    train_batch_pointer += batch_size\n",
    "    return x_out, y_out\n",
    "\n",
    "def LoadValBatch(batch_size):\n",
    "    global val_batch_pointer\n",
    "    x_out = []\n",
    "    y_out = []\n",
    "    for i in range(0, batch_size):\n",
    "        x_out.append(scipy.misc.imresize(scipy.misc.imread(val_xs[(val_batch_pointer + i) % num_val_images])[-150:], [66, 200]) / 255.0)\n",
    "        y_out.append([val_ys[(val_batch_pointer + i) % num_val_images]])\n",
    "    val_batch_pointer += batch_size\n",
    "    return x_out, y_out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'D:\\\\self car\\\\Autopilot-TensorFlow-master\\\\Autopilot-TensorFlow-master\\\\driving_dataset/40000.jpg'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xs[40000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original image size (256, 455, 3)\n",
      "After taking the last 150 rows i.e lower part of the images where road is present,  (150, 455, 3)\n",
      "After resizing the images into 66*200,  (66, 200, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:7: DeprecationWarning: `imread` is deprecated!\n",
      "`imread` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``imageio.imread`` instead.\n",
      "  import sys\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:12: DeprecationWarning: `imresize` is deprecated!\n",
      "`imresize` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``skimage.transform.resize`` instead.\n",
      "  if sys.path[0] == '':\n"
     ]
    }
   ],
   "source": [
    "# scipy.misc.imresize(scipy.misc.imread(train_xs[(train_batch_pointer + i) % num_train_images])[-150:], [66, 200]) / 255.0\n",
    "# you can break the whole line into parts like this\n",
    "# here (train_batch_pointer + i) % num_train_images => \"% num_train_images\" is used to make sure that the\n",
    "# (train_batch_pointer + i) values should not cross number of train images.\n",
    "\n",
    "# lets explain whats happening with the first images\n",
    "image_read = scipy.misc.imread(train_xs[0])\n",
    "print(\"original image size\",image_read.shape)\n",
    "\n",
    "print(\"After taking the last 150 rows i.e lower part of the images where road is present, \",image_read[-150:].shape)\n",
    "image_read = image_read[-150:]\n",
    "resized_image = scipy.misc.imresize(image_read, [66, 200])\n",
    "print(\"After resizing the images into 66*200, \",resized_image.shape)\n",
    "# 200/66 = 455/150 = 3.0303 => we are keeping aspect ratio when we are resizing it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: DeprecationWarning: `imread` is deprecated!\n",
      "`imread` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``imageio.imread`` instead.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: DeprecationWarning: `imresize` is deprecated!\n",
      "`imresize` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``skimage.transform.resize`` instead.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[[180, 162, 166],\n",
       "        [176, 172, 173],\n",
       "        [176, 176, 171],\n",
       "        ...,\n",
       "        [ 90,  88, 113],\n",
       "        [106,  93,  99],\n",
       "        [101, 103,  81]],\n",
       "\n",
       "       [[191, 188, 192],\n",
       "        [186, 193, 204],\n",
       "        [187, 196, 200],\n",
       "        ...,\n",
       "        [ 84,  82,  97],\n",
       "        [ 86,  88,  79],\n",
       "        [ 86, 101,  74]],\n",
       "\n",
       "       [[208, 201, 223],\n",
       "        [199, 212, 230],\n",
       "        [201, 212, 226],\n",
       "        ...,\n",
       "        [128, 124, 115],\n",
       "        [128, 126, 117],\n",
       "        [132, 126, 119]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[ 54,  43,  55],\n",
       "        [ 59,  43,  56],\n",
       "        [ 55,  41,  53],\n",
       "        ...,\n",
       "        [ 23,  24,  25],\n",
       "        [ 24,  25,  27],\n",
       "        [ 25,  26,  29]],\n",
       "\n",
       "       [[ 56,  36,  58],\n",
       "        [ 53,  35,  63],\n",
       "        [ 51,  39,  54],\n",
       "        ...,\n",
       "        [ 23,  25,  22],\n",
       "        [ 23,  26,  23],\n",
       "        [ 24,  27,  25]],\n",
       "\n",
       "       [[ 68,  37,  44],\n",
       "        [ 53,  41,  49],\n",
       "        [ 49,  49,  37],\n",
       "        ...,\n",
       "        [ 28,  25,  26],\n",
       "        [ 26,  23,  25],\n",
       "        [ 24,  22,  24]]], dtype=uint8)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scipy.misc.imresize(scipy.misc.imread(train_xs[0])[-150:], [66, 200])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "vgcc6iQobKHi"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed processing data.txt\n"
     ]
    }
   ],
   "source": [
    "# read images and steering angles from driving_dataset folder\n",
    "\n",
    "from __future__ import division\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "from scipy import pi\n",
    "from itertools import islice\n",
    "\n",
    "\n",
    "\n",
    "DATA_FOLDER = \"D:\\self car\\Autopilot-TensorFlow-master\\Autopilot-TensorFlow-master\\driving_dataset\" # change this to your folder\n",
    "TRAIN_FILE = os.path.join(DATA_FOLDER, 'data.txt')\n",
    "\n",
    "\n",
    "split =0.7\n",
    "X = []\n",
    "y = []\n",
    "LIMIT=1000\n",
    "with open(TRAIN_FILE) as fp:\n",
    "    for line in islice(fp, LIMIT):\n",
    "        path, angle = line.strip().split()\n",
    "        full_path = os.path.join(DATA_FOLDER, path)\n",
    "        X.append(full_path)\n",
    "        \n",
    "        # converting angle from degrees to radians\n",
    "        y.append(float(angle) * pi / 180 )\n",
    "\n",
    "\n",
    "y = np.array(y)\n",
    "print(\"Completed processing data.txt\")\n",
    "\n",
    "split_index = int(len(y)*0.7)\n",
    "\n",
    "train_y = y[:split_index]\n",
    "test_y = y[split_index:]\n",
    "\n",
    "          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\matplotlib\\axes\\_axes.py:6462: UserWarning: The 'normed' kwarg is deprecated, and has been replaced by the 'density' kwarg.\n",
      "  warnings.warn(\"The 'normed' kwarg is deprecated, and has been \"\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAAD+BJREFUeJzt3W+MpWV5x/Hvr+yq9d/SdCfRLssMTYmtGg26QSxJQ6KmSAm8qEZMin9as6nxD2tMWrEJ7PqqTRtFi5FslVoqwSZIzbZZqxhN1BcQhhVR2NpsdUam0DhCO2i1NZtefTFn4HT2zJwzM+fsmXPP95Oc8Jzz3POc65ldfnufa+7nmVQVkqS2/MK4C5AkDZ/hLkkNMtwlqUGGuyQ1yHCXpAYZ7pLUIMNdkhpkuEtSgwx3SWrQrnG98d69e2tmZmZcby9JE+n+++//UVVN9Rs3tnCfmZlhdnZ2XG8vSRMpyfwg42zLSFKDDHdJapDhLkkNMtwlqUGGuyQ1yHCXpAYZ7pLUIMNdkhpkuEtSg8Z2hepON3PTDPNLZ15oNr1nmrlDc2e/IElNMdzHZH5pnrqxzng9RzKGaiS1xraMJDWob7gn2Z/kq0lOJnkoyXU9xlyWZCnJA53HDaMpV5I0iEHaMqeB91fViSTPA+5PcndVPbxq3Ner6srhlyhJ2qi+M/eqeqyqTnS2fwycBPaNujBJ0uZtqOeeZAa4CLi3x+5XJ/lWki8keckaX38wyWyS2cXFxQ0XK0kazMDhnuS5wOeAQ1X15KrdJ4Dpqno58JfA53sdo6qOVtWBqjowNdX3F4lIkjZpoHBPspvlYL+9qu5avb+qnqyqn3S2jwO7k+wdaqWSpIENslomwKeAk1X14TXGvKAzjiQXd477+DALbdrMDCTL/5WkIRhktcylwLXAt5M80Hntg8D5AFV1C/AG4J1JTgM/A66pqjOv0FFv8/NQtRzwkjQEfcO9qr4BrJs6VXUzcPOwipIkbY1XqEpSgwx3SWqQ4S5JDTLcJalBhrskNchwl6QGGe6S1CDDXZIaZLhLUoMMd0lqkOEuSQ0y3CWpQYa7JDXIcJekBhnuktQgw12SGmS4S1KDDHdJapDhLkkNMtwlqUGGuyQ1yHCXpAYZ7pLUIMNdkhpkuEtSgwx3SWqQ4S5JDTLcJalBhrskNchwl6QGGe6S1KC+4Z5kf5KvJjmZ5KEk1/UYkyQfS3IqyYNJXjGaciVJg9g1wJjTwPur6kSS5wH3J7m7qh7uGvN64MLO41XAJzr/lSSNQd+Ze1U9VlUnOts/Bk4C+1YNuxq4rZbdA5yb5IVDr1aSNJAN9dyTzAAXAfeu2rUPeKTr+QJn/gMgSTpLBg73JM8FPgccqqonV+/u8SXV4xgHk8wmmV1cXNxYpZKkgQ0U7kl2sxzst1fVXT2GLAD7u56fBzy6elBVHa2qA1V1YGpqajP1SpIGMMhqmQCfAk5W1YfXGHYMeEtn1cwlwFJVPTbEOiVJGzDIaplLgWuBbyd5oPPaB4HzAarqFuA4cAVwCvgp8PbhlypJGlTfcK+qb9C7p949poB3DasoSdLWeIWqJDXIcJekBhnuktQgw12SGmS4S1KDDHdJapDhPibf/wiQLD+mp8ddjqTGDHIRk0ZgZgmoM26/I0lD4cxdkhpkuEtSgwx3SWqQ4S5JDTLcJalBhrskNchwl6QGGe6S1CDDXZIaZLhLUoMMd0lqkOEuSQ0y3CWpQYa7JDXIcJekBhnuktQgw12SGmS4S1KDDHdJapDhLkkNMtwlqUGGuyQ1yHCXpAb1Dfcktyb5YZLvrLH/siRLSR7oPG4YfpmSpI3YNcCYTwM3A7etM+brVXXlUCqSJG1Z35l7VX0NeOIs1CJJGpJh9dxfneRbSb6Q5CVDOqYkaZMGacv0cwKYrqqfJLkC+DxwYa+BSQ4CBwHOP//8Iby1JKmXLc/cq+rJqvpJZ/s4sDvJ3jXGHq2qA1V1YGpqaqtvLUlaw5bDPckLkqSzfXHnmI9v9biSpM3r25ZJcgdwGbA3yQJwI7AboKpuAd4AvDPJaeBnwDVVVSOrWJLUV99wr6o399l/M8tLJSVJ24RXqEpSgwx3SWqQ4S5JDTLcJalBhrskNchwl6QGGe6S1CDDXZIaZLhLUoMMd0lqkOEuSQ0y3CWpQYa7JDXIcJekBhnuktQgw12SGmS4S1KDDHdJapDhLkkNMtwlqUGGuyQ1yHCXpAYZ7pLUIMNdkhpkuEtSgwx3SWqQ4S5JDTLcJalBhrskNchwl6QGGe6S1KC+4Z7k1iQ/TPKdNfYnyceSnEryYJJXDL9MSdJGDDJz/zRw+Tr7Xw9c2HkcBD6x9bIkSVvRN9yr6mvAE+sMuRq4rZbdA5yb5IXDKlCStHHD6LnvAx7per7QeU2SNCbDCPf0eK16DkwOJplNMru4uDiEt5Yk9TKMcF8A9nc9Pw94tNfAqjpaVQeq6sDU1NQQ3lqS1Mswwv0Y8JbOqplLgKWqemwIx5UkbdKufgOS3AFcBuxNsgDcCOwGqKpbgOPAFcAp4KfA20dVrCRpMH3Dvare3Gd/Ae8aWkWSpC3zClVJapDhLkkNMtwlqUGGuyQ1yHCXpAYZ7pLUIMNdkhpkuEtSgwx3SWqQ4S5JDTLcJalBhrskNajvjcO2o5mbZphfmu+5b3rPNHOH5s5uQZK0zUxkuM8vzVM39vxlT+RIr18MJUk7i20ZSWqQ4S5JDTLcJalBhrskNchwl6QGGe6S1CDDXZIaZLhLUoMM97NtZgYS5vaMuxBtSefPkWR5W9pmJvIK1Yk2Pw9VXHAk9L7GVhOh8+cILAe8tM04c5ekBhnuktQgw12SGmS4S1KDDPdhcxWFpG3A1TLD5ioKSduAM3dJatBA4Z7k8iTfTXIqyQd67H9bksUkD3Qe7xh+qZKkQfVtyyQ5B/g48DpgAbgvybGqenjV0L+rqnePoEZJ0gYNMnO/GDhVVd+rqp8DnwWuHm1ZkqStGCTc9wGPdD1f6Ly22u8meTDJnUn2D6U6SdKmDBLuvZZ8rL4tyj8AM1X1MuDLwN/0PFByMMlsktnFxcWNVSqN0soSVpevqhGDhPsC0D0TPw94tHtAVT1eVf/TefpXwCt7HaiqjlbVgao6MDU1tZl6pdFYWcI6Pz/uSqShGCTc7wMuTHJBkmcA1wDHugckeWHX06uAk8MrUZK0UX1Xy1TV6STvBr4InAPcWlUPJfkQMFtVx4D3JrkKOA08AbxthDVLkvoY6ArVqjoOHF/12g1d29cD1w+3NEnSZnmFqiQ1yHvLbDPTe6bJkTMXKE3vmWbu0NzZL0jSRDLct5m1ArxX4EvSWmzLSFKDDHdJapDhLkkNMtwlqUGGu3Ye7yOjHcDVMtp5Vu4j469BVMOcuUtSgwx37QwrrZgEpqc3/7W2cjQhbMtoZ1hpxWz1a23laEI4c5ekBhnuUrfpaVswaoJtGanb3NzT27ZgNMGcuUtSgwz3Uer+iL/ZlRraOFe3SLZlRqr7I77OHle3SM7cJalFhvt212kx1GFsMfSz0o7pbn2ttMZ6tcO622br7R/0eNI2YltmxGZummF+af6M16f3DBgOnRZDjoQ6fOZx1KXXhUrrtcb6tc167bfVpglhuI/Y/NI8deMmr4yUpE2yLTNJVloCO7U9070KxtUw0rqcuU+SlZbATl0B0qvtslO/F1IfztwlqUGGuyQ1yHDfTryitbdeSxxX9FvOKO1Q9ty3E5fZ9bbevdj9nkk9Ge4TYnrPNDmy/MPDgqe2p/dMM3dobnyFSdqWbMtMiLlDc9SN9dSa+ZXtXhdIbWv9buq1st8ljtKW7JiZ+3pXijrzPYv63dRrZb9LHKUtGSjck1wOfBQ4B/hkVf3pqv3PBG4DXgk8DrypquaGW+pgutsXq1/vdaVor7GSNOn6hnuSc4CPA68DFoD7khyrqoe7hv0B8B9V9WtJrgH+DHjTKAruZ6Oz8LX+Mdis7n74yvGHbmWFSOf9ONy7/rk9cMH7lre//xGYWVp+7bLDnU8rMzPLM+XVx57rsw967x+09h7nccb+7n2ugtGEGmfHYJCZ+8XAqar6HkCSzwJXA93hfjVwuLN9J3BzklRt9tfNnz1D/wYfzujvJdO1QiRHer/f8o3GeHrf4UAVM8nTf9nWu+Kz39Wg661g2cR5bGifNCHWurfU2egYDBLu+4BHup4vAK9aa0xVnU6yBPwy8KNhFKm1rdeGgt4z65WvWf0pA57+5DHIipy1ZiU7Ta/v42ZN0vd6o7VO0rkNy0g+uQ8o/SbXSd4I/HZVvaPz/Frg4qp6T9eYhzpjFjrP/7Uz5vFVxzoIHOw8fRHw3QFq3MvO+EdiJ5znTjhH2BnnuRPOEbbneU5X1VS/QYPM3BeA/V3PzwMeXWPMQpJdwB7gidUHqqqjwNEB3vMpSWar6sBGvmYS7YTz3AnnCDvjPHfCOcJkn+cg69zvAy5MckGSZwDXAMdWjTkGvLWz/QbgK5PQb5ekVvWduXd66O8GvsjyUshbq+qhJB8CZqvqGPAp4G+TnGJ5xn7NKIuWJK1voHXuVXUcOL7qtRu6tv8beONwS3vKhto4E2wnnOdOOEfYGee5E84RJvg8+/5AVZI0eby3jCQ1aCLCPcmfJ/nnJA8m+fsk5467pmFJcnmS7yY5leQD465nFJLsT/LVJCeTPJTkunHXNCpJzknyzST/OO5aRiXJuUnu7Pw/eTLJq8dd07AleV/n7+p3ktyR5FnjrmmjJiLcgbuBl1bVy4B/Aa4fcz1D0XVrh9cDLwbenOTF461qJE4D76+q3wAuAd7V6HkCXAecHHcRI/ZR4J+q6teBl9PY+SbZB7wXOFBVL2V5IcnELRKZiHCvqi9V1enO03tYXmvfgqdu7VBVPwdWbu3QlKp6rKpOdLZ/zHIY7BtvVcOX5Dzgd4BPjruWUUnyfOC3WF4hR1X9vKr+c7xVjcQu4Bc71+08mzOv7dn2JiLcV/l94AvjLmJIet3aobnQ65ZkBrgIuHe8lYzETcAfAf877kJG6FeBReCvO+2nTyZ5zriLGqaq+jfgL4AfAI8BS1X1pfFWtXHbJtyTfLnT31r9uLprzJ+w/BH/9vFVOlS9bkjS7PKlJM8FPgccqqonx13PMCW5EvhhVd0/7lpGbBfwCuATVXUR8F9AUz8rSvJLLH+CvgD4FeA5SX5vvFVt3Lb5ZR1V9dr19id5K3Al8JqGrn4d5NYOTUiym+Vgv72q7hp3PSNwKXBVkiuAZwHPT/KZqpq4UOhjAVioqpVPXnfSWLgDrwW+X1WLAEnuAn4T+MxYq9qgbTNzX0/nl4X8MXBVVf103PUM0SC3dph4ScJyj/ZkVX143PWMQlVdX1XnVdUMy3+OX2kw2KmqfwceSfKizkuv4f/f/rsFPwAuSfLszt/d1zCBPzTeNjP3Pm4Gngncvfy95p6q+sPxlrR1a93aYcxljcKlwLXAt5M80Hntg50rnzV53gPc3pmQfA94+5jrGaqqujfJncAJltvA32QCr1T1ClVJatBEtGUkSRtjuEtSgwx3SWqQ4S5JDTLcJalBhrskNchwl6QGGe6S1KD/A/+dUv/UV1kvAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy;\n",
    "\n",
    "# PDF of train and test 'y' values. \n",
    "import matplotlib.pyplot as plt \n",
    "plt.hist(train_y, bins=50, normed=1, color='green', histtype ='step');\n",
    "plt.hist(test_y, bins=50, normed=1, color='red', histtype ='step');\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test_MSE(MEAN):3.960951\n",
      "Test_MSE(ZERO):4.153462\n"
     ]
    }
   ],
   "source": [
    "#Model 0: Base line Model: y_test_pred = mean(y_train_i) \n",
    "train_mean_y = np.mean(train_y)\n",
    "\n",
    "print('Test_MSE(MEAN):%f' % np.mean(np.square(test_y-train_mean_y)) )\n",
    "\n",
    "print('Test_MSE(ZERO):%f' % np.mean(np.square(test_y-0.0)) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining the architecture of the Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From <ipython-input-2-db1dd83d7446>:58: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import scipy\n",
    "\n",
    "def weight_variable(shape):\n",
    "  initial = tf.truncated_normal(shape, stddev=0.1)\n",
    "  return tf.Variable(initial)\n",
    "\n",
    "def bias_variable(shape):\n",
    "  initial = tf.constant(0.1, shape=shape)\n",
    "  return tf.Variable(initial)\n",
    "\n",
    "def conv2d(x, W, stride):\n",
    "  return tf.nn.conv2d(x, W, strides=[1, stride, stride, 1], padding='VALID')\n",
    "\n",
    "x = tf.placeholder(tf.float32, shape=[None, 66, 200, 3])\n",
    "y_ = tf.placeholder(tf.float32, shape=[None, 1])\n",
    "\n",
    "x_image = x\n",
    "\n",
    "#first convolutional layer\n",
    "W_conv1 = weight_variable([5, 5, 3, 24])\n",
    "b_conv1 = bias_variable([24])\n",
    "\n",
    "h_conv1 = tf.nn.relu(conv2d(x_image, W_conv1, 2) + b_conv1)\n",
    "\n",
    "#second convolutional layer\n",
    "W_conv2 = weight_variable([5, 5, 24, 36])\n",
    "b_conv2 = bias_variable([36])\n",
    "\n",
    "h_conv2 = tf.nn.relu(conv2d(h_conv1, W_conv2, 2) + b_conv2)\n",
    "\n",
    "#third convolutional layer\n",
    "W_conv3 = weight_variable([5, 5, 36, 48])\n",
    "b_conv3 = bias_variable([48])\n",
    "\n",
    "h_conv3 = tf.nn.relu(conv2d(h_conv2, W_conv3, 2) + b_conv3)\n",
    "\n",
    "#fourth convolutional layer\n",
    "W_conv4 = weight_variable([3, 3, 48, 64])\n",
    "b_conv4 = bias_variable([64])\n",
    "\n",
    "h_conv4 = tf.nn.relu(conv2d(h_conv3, W_conv4, 1) + b_conv4)\n",
    "\n",
    "#fifth convolutional layer\n",
    "W_conv5 = weight_variable([3, 3, 64, 64])\n",
    "b_conv5 = bias_variable([64])\n",
    "\n",
    "h_conv5 = tf.nn.relu(conv2d(h_conv4, W_conv5, 1) + b_conv5)\n",
    "\n",
    "#FCL 1\n",
    "W_fc1 = weight_variable([1152, 1164])\n",
    "b_fc1 = bias_variable([1164])\n",
    "\n",
    "h_conv5_flat = tf.reshape(h_conv5, [-1, 1152])\n",
    "h_fc1 = tf.nn.relu(tf.matmul(h_conv5_flat, W_fc1) + b_fc1)\n",
    "\n",
    "keep_prob = tf.placeholder(tf.float32)\n",
    "h_fc1_drop = tf.nn.dropout(h_fc1, keep_prob)\n",
    "\n",
    "#FCL 2\n",
    "W_fc2 = weight_variable([1164, 100])\n",
    "b_fc2 = bias_variable([100])\n",
    "\n",
    "h_fc2 = tf.nn.relu(tf.matmul(h_fc1_drop, W_fc2) + b_fc2)\n",
    "\n",
    "h_fc2_drop = tf.nn.dropout(h_fc2, keep_prob)\n",
    "\n",
    "#FCL 3\n",
    "W_fc3 = weight_variable([100, 50])\n",
    "b_fc3 = bias_variable([50])\n",
    "\n",
    "h_fc3 = tf.nn.relu(tf.matmul(h_fc2_drop, W_fc3) + b_fc3)\n",
    "\n",
    "h_fc3_drop = tf.nn.dropout(h_fc3, keep_prob)\n",
    "\n",
    "#FCL 3\n",
    "W_fc4 = weight_variable([50, 10])\n",
    "b_fc4 = bias_variable([10])\n",
    "\n",
    "h_fc4 = tf.nn.relu(tf.matmul(h_fc3_drop, W_fc4) + b_fc4)\n",
    "\n",
    "h_fc4_drop = tf.nn.dropout(h_fc4, keep_prob)\n",
    "\n",
    "#Output\n",
    "W_fc5 = weight_variable([10, 1])\n",
    "b_fc5 = bias_variable([1])\n",
    "\n",
    "y = tf.multiply(tf.nn.relu(tf.matmul(h_fc4_drop, W_fc5) + b_fc5), 2) #scale the atan output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow.core.protobuf import saver_pb2\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "LOGDIR = \"D:\\self car\\Autopilot-TensorFlow-master\\Autopilot-TensorFlow-master\\save\"\n",
    "\n",
    "sess = tf.InteractiveSession()\n",
    "\n",
    "L2NormConst = 0.001\n",
    "\n",
    "train_vars = tf.trainable_variables()\n",
    "\n",
    "loss = tf.reduce_mean(tf.square(tf.subtract(y_, y))) + tf.add_n([tf.nn.l2_loss(v) for v in train_vars]) * L2NormConst\n",
    "train_step = tf.train.AdamOptimizer(1e-3).minimize(loss)\n",
    "sess.run(tf.initialize_all_variables())\n",
    "\n",
    "# create a summary to monitor cost tensor\n",
    "tf.summary.scalar(\"loss\", loss)\n",
    "# merge all summaries into a single op\n",
    "merged_summary_op =  tf.summary.merge_all()\n",
    "\n",
    "saver = tf.train.Saver(write_version = saver_pb2.SaverDef.V1)\n",
    "\n",
    "# op to write logs to Tensorboard\n",
    "logs_path = \"D:\\self car\\Autopilot-TensorFlow-master\\Autopilot-TensorFlow-master\\logs\"\n",
    "summary_writer = tf.summary.FileWriter(logs_path, graph=tf.get_default_graph())\n",
    "\n",
    "epochs = 30\n",
    "batch_size = 100\n",
    "\n",
    "# train over the dataset about 30 times\n",
    "for epoch in range(epochs):\n",
    "    for i in range(int(num_images/batch_size)):\n",
    "        xs, ys = LoadTrainBatch(batch_size)\n",
    "        train_step.run(feed_dict={x: xs, y_: ys, keep_prob: 0.5})\n",
    "        if i % 10 == 0:\n",
    "            xs, ys = LoadValBatch(batch_size)\n",
    "            loss_value = loss.eval(feed_dict={x:xs, y_: ys, keep_prob: 1.0})\n",
    "            print(\"Epoch: %d, Step: %d, Loss: %g\" % (epoch, epoch * batch_size + i, loss_value))\n",
    "\n",
    "        # write logs at every iteration\n",
    "        summary = merged_summary_op.eval(feed_dict={x:xs, y_: ys, keep_prob: 1.0})\n",
    "        summary_writer.add_summary(summary, epoch * num_images/batch_size + i)\n",
    "\n",
    "        if i % batch_size == 0:\n",
    "            checkpoint_path = os.path.join(LOGDIR, \"model.ckpt\")\n",
    "            filename = saver.save(sess, checkpoint_path)\n",
    "    print(\"one_epoch_done\")\n",
    "\n",
    "print(\"Run the command line:\\n\" \\\n",
    "          \"--> tensorboard --logdir=./logs \" \\\n",
    "          \"\\nThen open http://0.0.0.0:6006/ into your web browser\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing the output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip3 install opencv-python\n",
    "\n",
    "import tensorflow as tf\n",
    "import scipy.misc\n",
    "\n",
    "import cv2\n",
    "from subprocess import call\n",
    "import math\n",
    "\n",
    "sess = tf.InteractiveSession()\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "saver.restore(sess, \"D:\\self car\\Autopilot-TensorFlow-master\\Autopilot-TensorFlow-master\\save\\model.ckpt\")\n",
    "\n",
    "img = cv2.imread(\"D:\\self car\\Autopilot-TensorFlow-master\\Autopilot-TensorFlow-master\\steering_wheel_image.jpg\",0)\n",
    "rows,cols = img.shape\n",
    "\n",
    "smoothed_angle = 0\n",
    "\n",
    "\n",
    "#read data.txt\n",
    "xs = []\n",
    "ys = []\n",
    "with open(\"D:\\self car\\Autopilot-TensorFlow-master\\Autopilot-TensorFlow-master\\driving_dataset\\data.txt\") as f:\n",
    "    for line in f:\n",
    "        xs.append(\"D:\\self car\\Autopilot-TensorFlow-master\\Autopilot-TensorFlow-master\\driving_dataset/\" + line.split()[0])\n",
    "        #the paper by Nvidia uses the inverse of the turning radius,\n",
    "        #but steering wheel angle is proportional to the inverse of turning radius\n",
    "        #so the steering wheel angle in radians is used as the output\n",
    "        ys.append(float(line.split()[1]) * scipy.pi / 180)\n",
    "\n",
    "#get number of images\n",
    "num_images = len(xs)\n",
    "\n",
    "\n",
    "i = math.ceil(num_images*0.7)\n",
    "print(\"Starting frameofvideo:\" +str(i))\n",
    "\n",
    "while(cv2.waitKey(10) != ord('q')):\n",
    "    full_image = scipy.misc.imread(\"D:\\self car\\Autopilot-TensorFlow-master\\Autopilot-TensorFlow-master\\driving_dataset/\" + str(i) + \".jpg\", mode=\"RGB\")\n",
    "    image = scipy.misc.imresize(full_image[-150:], [66, 200]) / 255.0\n",
    "    degrees = y.eval(feed_dict={x: [image], keep_prob: 1.0})[0][0] * 180.0 / scipy.pi\n",
    "    #call(\"clear\")\n",
    "    #print(\"Predicted Steering angle: \" + str(degrees))\n",
    "    print(\"Steering angle: \" + str(degrees) + \" (pred)\\t\" + str(ys[i]*180/scipy.pi) + \" (actual)\")\n",
    "    cv2.imshow(\"frame\", cv2.cvtColor(full_image, cv2.COLOR_RGB2BGR))\n",
    "    #make smooth angle transitions by turning the steering wheel based on the difference of the current angle\n",
    "    #and the predicted angle\n",
    "    smoothed_angle += 0.2 * pow(abs((degrees - smoothed_angle)), 2.0 / 3.0) * (degrees - smoothed_angle) / abs(degrees - smoothed_angle)\n",
    "    M = cv2.getRotationMatrix2D((cols/2,rows/2),-smoothed_angle,1)\n",
    "    dst = cv2.warpAffine(img,M,(cols,rows))\n",
    "    cv2.imshow(\"steering wheel\", dst)\n",
    "    i += 1\n",
    "\n",
    "cv2.destroyAllWindows()\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "default_view": {},
   "name": "Self_driving_car.ipynb",
   "provenance": [],
   "version": "0.3.2",
   "views": {}
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
